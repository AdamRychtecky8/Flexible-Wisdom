{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fd5639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/AdamR/OneDrive/UCSB/VIU/HonorsThesis/data')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd() / \"notebooks\"))  # so we can import _utils from notebooks/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from _utils import get_data_dir\n",
    "\n",
    "DATA_DIR = get_data_dir()\n",
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55458ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(DATA_DIR.glob(\"**/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4105e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded datasets: ['50_50', '80_20', '100_0']\n"
     ]
    }
   ],
   "source": [
    "# === Load human + model CSVs for 50_50, 80_20, and 100_0 datasets ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = DATA_DIR  # already defined in your environment\n",
    "FOLDERS = [\"50_50\", \"80_20\", \"100_0\"]\n",
    "\n",
    "def safe_read_csv(path: Path, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Robust CSV reader with fallback parsing.\"\"\"\n",
    "    defaults = dict(low_memory=False, encoding_errors=\"ignore\")\n",
    "    defaults.update(kwargs)\n",
    "    try:\n",
    "        return pd.read_csv(path, **defaults)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, engine=\"python\", sep=None, **defaults)\n",
    "\n",
    "def load_dataset(folder: Path) -> dict:\n",
    "    \"\"\"Load human_data.csv and all model decision CSVs inside 'decisions/'.\"\"\"\n",
    "    human_path = folder / \"human_data.csv\"\n",
    "    decisions_dir = folder / \"decisions\"\n",
    "\n",
    "    if not human_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing human_data.csv in {folder}\")\n",
    "    if not decisions_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing 'decisions/' subfolder in {folder}\")\n",
    "\n",
    "    # Load human data\n",
    "    human_df = safe_read_csv(human_path)\n",
    "\n",
    "    # Load each model file\n",
    "    models = {}\n",
    "    for csv_path in sorted(decisions_dir.glob(\"*.csv\")):\n",
    "        model_name = csv_path.stem\n",
    "        models[model_name] = safe_read_csv(csv_path)\n",
    "\n",
    "    return {\n",
    "        \"human\": human_df,\n",
    "        \"human_path\": human_path,\n",
    "        \"models\": models,\n",
    "        \"model_paths\": {m: csv_path for m, csv_path in zip(models.keys(), sorted(decisions_dir.glob('*.csv')))}\n",
    "    }\n",
    "\n",
    "# === Main loading loop ===\n",
    "datasets: dict[str, dict] = {}\n",
    "records = []\n",
    "\n",
    "for name in FOLDERS:\n",
    "    folder = ROOT / name\n",
    "    if not folder.exists():\n",
    "        print(f\"⚠️ Warning: Folder '{name}' not found under {ROOT}\")\n",
    "        continue\n",
    "\n",
    "    data_bundle = load_dataset(folder)\n",
    "    datasets[name] = data_bundle\n",
    "\n",
    "    # Record human file\n",
    "    h = data_bundle[\"human\"]\n",
    "    records.append({\n",
    "        \"dataset\": name,\n",
    "        \"kind\": \"human\",\n",
    "        \"name\": \"human_data\",\n",
    "        \"n_rows\": len(h),\n",
    "        \"n_cols\": h.shape[1],\n",
    "        \"path\": str(data_bundle[\"human_path\"].resolve())\n",
    "    })\n",
    "\n",
    "    # Record model files\n",
    "    for mname, mdf in data_bundle[\"models\"].items():\n",
    "        records.append({\n",
    "            \"dataset\": name,\n",
    "            \"kind\": \"model\",\n",
    "            \"name\": mname,\n",
    "            \"n_rows\": len(mdf),\n",
    "            \"n_cols\": mdf.shape[1],\n",
    "            \"path\": str((folder / \"decisions\" / f\"{mname}.csv\").resolve())\n",
    "        })\n",
    "\n",
    "# === Summary table ===\n",
    "assignment_index = pd.DataFrame.from_records(records).sort_values(\n",
    "    [\"dataset\", \"kind\", \"name\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Loaded datasets: {list(datasets.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c54c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column titles\n",
    "\n",
    "def get_csv_columns(csv_path):\n",
    "    \"\"\"\n",
    "    Return a list of column names from a CSV file.\n",
    "    Accepts either a string/Path to a file or a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(csv_path, pd.DataFrame):\n",
    "        return list(csv_path.columns)\n",
    "    \n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {csv_path}\")\n",
    "    \n",
    "    # Read only the header row\n",
    "    df = pd.read_csv(csv_path, nrows=0, encoding_errors=\"ignore\")\n",
    "    return list(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15e609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stimID</th>\n",
       "      <th>condition</th>\n",
       "      <th>response</th>\n",
       "      <th>side_selected</th>\n",
       "      <th>cue_points</th>\n",
       "      <th>line1_angle</th>\n",
       "      <th>line2_angle</th>\n",
       "      <th>valid_cue</th>\n",
       "      <th>TP</th>\n",
       "      <th>participantID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>condition_2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>1.921956</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>845</td>\n",
       "      <td>condition_2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>condition_2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>6.508956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>condition_2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.775056</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>condition_2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>19.885165</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stimID    condition  response  side_selected  cue_points  line1_angle  \\\n",
       "0     100  condition_2         6              1           2    14.314827   \n",
       "1     845  condition_2         5              1           2    15.054317   \n",
       "2     245  condition_2         4              1           1    14.314827   \n",
       "3      72  condition_2         4              2           2     8.775056   \n",
       "4     469  condition_2         4              2           2     4.222230   \n",
       "\n",
       "   line2_angle  valid_cue    TP participantID  \n",
       "0     1.921956      False  True            SA  \n",
       "1     4.222230      False  True            SA  \n",
       "2     6.508956       True  True            SA  \n",
       "3    15.054317       True  True            SA  \n",
       "4    19.885165       True  True            SA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stimID', 'condition', 'response', 'side_selected', 'cue_points', 'line1_angle', 'line2_angle', 'valid_cue', 'TP', 'participantID']\n"
     ]
    }
   ],
   "source": [
    "#Get each dataset into df variables\n",
    "\n",
    "human50_50 = datasets[\"50_50\"][\"human\"]\n",
    "human80_20 = datasets[\"80_20\"][\"human\"]\n",
    "human100_0 = datasets[\"100_0\"][\"human\"]\n",
    "human50_50_columns = get_csv_columns(human50_50)\n",
    "\n",
    "human_all = pd.concat([human50_50, human80_20, human100_0], ignore_index=True)\n",
    "\n",
    "claude35haiku = datasets[\"50_50\"][\"models\"]\n",
    "\n",
    "display(human50_50.head(5))\n",
    "print(human50_50_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc3d72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamR\\AppData\\Local\\Temp\\ipykernel_15224\\2160626346.py:29: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: _compute_metrics(g))\n",
      "C:\\Users\\AdamR\\AppData\\Local\\Temp\\ipykernel_15224\\2160626346.py:37: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: _compute_metrics(g))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>fa_rate</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AG</td>\n",
       "      <td>0.824667</td>\n",
       "      <td>0.500667</td>\n",
       "      <td>0.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AW</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>0.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BC</td>\n",
       "      <td>0.674667</td>\n",
       "      <td>0.603333</td>\n",
       "      <td>0.535667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CY</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.501333</td>\n",
       "      <td>0.537333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GS</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.537000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HG</td>\n",
       "      <td>0.694667</td>\n",
       "      <td>0.379333</td>\n",
       "      <td>0.657667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JH</td>\n",
       "      <td>0.631333</td>\n",
       "      <td>0.279333</td>\n",
       "      <td>0.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KM</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>0.205333</td>\n",
       "      <td>0.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KZ</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.138000</td>\n",
       "      <td>0.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SA</td>\n",
       "      <td>0.744667</td>\n",
       "      <td>0.582667</td>\n",
       "      <td>0.581000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UR</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participantID  hit_rate   fa_rate  accuracy\n",
       "0             AG  0.824667  0.500667  0.662000\n",
       "1             AW  0.703333  0.461333  0.621000\n",
       "2             AZ  0.646000  0.586000  0.530000\n",
       "3             BC  0.674667  0.603333  0.535667\n",
       "4             CY  0.576000  0.501333  0.537333\n",
       "5             GS  0.530000  0.456000  0.537000\n",
       "6             HG  0.694667  0.379333  0.657667\n",
       "7             JH  0.631333  0.279333  0.676000\n",
       "8             KM  0.647333  0.205333  0.721000\n",
       "9             KZ  0.372000  0.138000  0.617000\n",
       "10            SA  0.744667  0.582667  0.581000\n",
       "11            UR  0.870667  0.562667  0.654000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HUMAN_DF expected columns:\n",
    "# ['stimID', 'participantID', 'response', 'TP', 'condition']\n",
    "# response is a 1–6 confidence rating (>= threshold => \"present\")\n",
    "\n",
    "def _compute_metrics(g, choice_col=\"present_choice\"):\n",
    "    n_signal = int((g[\"TP\"] == 1).sum())\n",
    "    n_noise  = int((g[\"TP\"] == 0).sum())\n",
    "    n_total  = int(len(g))\n",
    "    hit_rate = float(np.mean(g.loc[g[\"TP\"] == 1, choice_col])) if n_signal > 0 else np.nan\n",
    "    fa_rate  = float(np.mean(g.loc[g[\"TP\"] == 0, choice_col])) if n_noise  > 0 else np.nan\n",
    "    acc      = float(np.mean(g[choice_col] == g[\"TP\"])) if n_total > 0 else np.nan\n",
    "    return pd.Series({\n",
    "        \"hit_rate\": hit_rate, \"fa_rate\": fa_rate, \"accuracy\": acc,\n",
    "        \"n_signal\": n_signal, \"n_noise\": n_noise, \"n_total\": n_total\n",
    "    })\n",
    "\n",
    "def human_metrics_per_participant(HUMAN_DF: pd.DataFrame, threshold: int = 4):\n",
    "    df = HUMAN_DF.copy()\n",
    "    df[\"TP\"] = pd.to_numeric(df[\"TP\"], errors=\"coerce\").astype(int)\n",
    "    df[\"response\"] = pd.to_numeric(df[\"response\"], errors=\"coerce\")\n",
    "    df[\"present_choice\"] = (df[\"response\"] >= threshold).astype(int)\n",
    "\n",
    "    # Per-condition per-participant\n",
    "    per_cond = (\n",
    "        df.groupby([\"participantID\", \"condition\"], as_index=False)\n",
    "          .apply(lambda g: _compute_metrics(g))\n",
    "          .reset_index(drop=True)\n",
    "          .sort_values([\"participantID\", \"condition\"])\n",
    "    )\n",
    "\n",
    "    # Overall (across all conditions) per-participant\n",
    "    overall = (\n",
    "        df.groupby([\"participantID\"], as_index=False)\n",
    "          .apply(lambda g: _compute_metrics(g))\n",
    "          .reset_index(drop=True)\n",
    "          .assign(condition=\"ALL\")\n",
    "          .sort_values([\"participantID\"])\n",
    "    )\n",
    "\n",
    "    return per_cond, overall\n",
    "human_per_cond, human_overall = human_metrics_per_participant(human_all, threshold=4)\n",
    "display(human_overall[[\"participantID\", \"hit_rate\", \"fa_rate\", \"accuracy\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5741a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human majority-vote accuracy — 50/50: 0.6820 (unique trials: 1000)\n",
      "Human majority-vote accuracy — 80/20: 0.6650 (unique trials: 1000)\n",
      "Human majority-vote accuracy — 100/0: 0.7810 (unique trials: 1000)\n",
      "\n",
      "Human majority-vote accuracy — COMBINED: 0.7093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>participants_per_trial</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100/0</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50/50</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80/20</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  trials  participants_per_trial  accuracy\n",
       "0     100/0    1000                    12.0     0.781\n",
       "1     50/50    1000                    12.0     0.682\n",
       "2     80/20    1000                    12.0     0.665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Majority-vote accuracy for three HUMAN DataFrames, then combined\n",
    "# Expects in-memory DataFrames:\n",
    "#   human50_50, human80_20, human100_0\n",
    "#\n",
    "# Assumed schema in each df (same as before):\n",
    "#   stimID, condition, response (1–6), side_selected, cue_points,\n",
    "#   line1_angle, line2_angle, valid_cue (0|1), TP (0|1), participantID\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_trial_table(df: pd.DataFrame, cond_label: str | None = None, tie_rule: str = \">\"):\n",
    "    \"\"\"\n",
    "    Build a trial-level table with majority-vote prediction per (stimID, condition),\n",
    "    with truth defined per (stimID, condition). Raw uniqueness is enforced at\n",
    "    (stimID, condition, participantID).\n",
    "    \n",
    "    tie_rule: \">\" means ties (==0.5) -> 0 (absent); \">=\" means ties -> 1 (present).\n",
    "    If cond_label is provided, it overrides/sets the 'condition' for all trials in df.\n",
    "    Returns: (trial_table: pd.DataFrame, overall_acc: float)\n",
    "    \"\"\"\n",
    "    required = {\n",
    "        \"stimID\", \"response\", \"TP\", \"participantID\",\n",
    "        \"side_selected\", \"cue_points\", \"line1_angle\", \"line2_angle\", \"valid_cue\"\n",
    "    }\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure 'condition' present (use override if provided)\n",
    "    if cond_label is not None:\n",
    "        df[\"condition\"] = cond_label\n",
    "    elif \"condition\" not in df.columns:\n",
    "        raise KeyError(\"Column 'condition' missing and no cond_label provided.\")\n",
    "\n",
    "    # Parse response (map 1–6 -> binary present/absent)\n",
    "    if not np.issubdtype(df[\"response\"].dtype, np.number):\n",
    "        df[\"response\"] = pd.to_numeric(df[\"response\"], errors=\"coerce\")\n",
    "    if df[\"response\"].isna().any():\n",
    "        bad = df.loc[df[\"response\"].isna(), [\"stimID\", \"participantID\"]].drop_duplicates()\n",
    "        raise ValueError(\n",
    "            f\"Some 'response' values could not be parsed as numbers (1–6). \"\n",
    "            f\"Examples (stimID, participantID): {bad.head(5).to_dict('records')}\"\n",
    "        )\n",
    "    df[\"human_decision\"] = (df[\"response\"] >= 4).astype(int)\n",
    "\n",
    "    # --- Enforce raw uniqueness at (stimID, condition, participantID) ---\n",
    "    # If a participant has multiple rows for the same (stimID, condition),\n",
    "    # collapse to that participant's MEAN binary decision for that trial.\n",
    "    per_participant = (\n",
    "        df.groupby([\"stimID\", \"condition\", \"participantID\"], as_index=False)\n",
    "          .agg(human_decision=(\"human_decision\", \"mean\"),\n",
    "               TP=(\"TP\", lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean()))))\n",
    "    )\n",
    "    # human_decision is in [0,1]; keep as float until voting\n",
    "\n",
    "    # Majority vote per (stimID, condition) across participants\n",
    "    prop_present = (\n",
    "        per_participant.groupby([\"stimID\", \"condition\"], as_index=False)[\"human_decision\"]\n",
    "                       .mean()\n",
    "                       .rename(columns={\"human_decision\": \"prop_present\"})\n",
    "    )\n",
    "    if tie_rule not in {\">\", \">=\"}:\n",
    "        raise ValueError(\"tie_rule must be '>' or '>='.\")\n",
    "    prop_present[\"pred\"] = (\n",
    "        (prop_present[\"prop_present\"] >= 0.5) if tie_rule == \">=\" else (prop_present[\"prop_present\"] > 0.5)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Truth per (stimID, condition) from raw df (mode fallback)\n",
    "    tp_per_trial = df.groupby([\"stimID\", \"condition\"])[\"TP\"]\n",
    "    tp_mode = tp_per_trial.agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean()))).astype(int)\n",
    "    tp_incons = tp_per_trial.nunique()\n",
    "    n_bad = int((tp_incons > 1).sum())\n",
    "    if n_bad > 0:\n",
    "        print(f\"Warning: {n_bad} (stimID, condition) group(s) had inconsistent TP; using per-group mode.\")\n",
    "\n",
    "    # Number of unique participants who voted per (stimID, condition)\n",
    "    n_voters = per_participant.groupby([\"stimID\", \"condition\"])[\"participantID\"].nunique().rename(\"n_participants\")\n",
    "\n",
    "    # Assemble trial-level table\n",
    "    trial_table = (\n",
    "        prop_present.merge(tp_mode.rename(\"truth\"), on=[\"stimID\", \"condition\"], how=\"left\")\n",
    "                    .merge(n_voters, on=[\"stimID\", \"condition\"], how=\"left\")\n",
    "                    .drop(columns=[\"prop_present\"])\n",
    "                    .sort_values([\"condition\", \"stimID\"])\n",
    "                    .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # Accuracy\n",
    "    overall_acc = (trial_table[\"pred\"] == trial_table[\"truth\"]).mean()\n",
    "\n",
    "    # Composite key to protect uniqueness across conditions\n",
    "    trial_table[\"trial_key\"] = trial_table[\"condition\"].astype(str) + \"|\" + trial_table[\"stimID\"].astype(str)\n",
    "\n",
    "    return trial_table, float(overall_acc)\n",
    "\n",
    "\n",
    "# ---- Compute for each condition-specific DataFrame ----\n",
    "tt_50, acc_50 = compute_trial_table(human50_50, cond_label=\"50/50\", tie_rule=\">\")\n",
    "tt_80, acc_80 = compute_trial_table(human80_20, cond_label=\"80/20\", tie_rule=\">\")\n",
    "tt_100, acc_100 = compute_trial_table(human100_0, cond_label=\"100/0\", tie_rule=\">\")\n",
    "\n",
    "print(f\"Human majority-vote accuracy — 50/50: {acc_50:.4f} (unique trials: {tt_50[['stimID','condition']].drop_duplicates().shape[0]})\")\n",
    "print(f\"Human majority-vote accuracy — 80/20: {acc_80:.4f} (unique trials: {tt_80[['stimID','condition']].drop_duplicates().shape[0]})\")\n",
    "print(f\"Human majority-vote accuracy — 100/0: {acc_100:.4f} (unique trials: {tt_100[['stimID','condition']].drop_duplicates().shape[0]})\")\n",
    "\n",
    "# ---- Combine and summarize ----\n",
    "combined = pd.concat([tt_50, tt_80, tt_100], ignore_index=True)\n",
    "\n",
    "# Sanity: check that combined has unique (stimID, condition) via trial_key\n",
    "if combined[\"trial_key\"].duplicated().any():\n",
    "    dups = combined.loc[combined[\"trial_key\"].duplicated(), \"trial_key\"].nunique()\n",
    "    print(f\"Note: {dups} duplicated trial_key values found in combined data.\")\n",
    "\n",
    "overall_acc = (combined[\"pred\"] == combined[\"truth\"]).mean()\n",
    "\n",
    "by_condition = (\n",
    "    combined.assign(correct=lambda x: (x[\"pred\"] == x[\"truth\"]).astype(int))\n",
    "            .groupby(\"condition\", as_index=False)\n",
    "            .agg(trials=(\"stimID\", \"nunique\"),\n",
    "                 participants_per_trial=(\"n_participants\", \"mean\"),\n",
    "                 accuracy=(\"correct\", \"mean\"))\n",
    "            .sort_values(\"condition\")\n",
    ")\n",
    "\n",
    "print(f\"\\nHuman majority-vote accuracy — COMBINED: {overall_acc:.4f}\")\n",
    "display(by_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88e3c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority-with-Exceptions (present≥6; priority=present; tie='>')\n",
      "Overall accuracy: 0.6433 | Trials (stimID×condition): 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamR\\AppData\\Local\\Temp\\ipykernel_15224\\2488676496.py:101: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(decide_group_pred_from_pp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>participants_per_trial</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pct_exception</th>\n",
       "      <th>pct_present_exc</th>\n",
       "      <th>pct_absent_exc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     condition  trials  participants_per_trial  accuracy  pct_exception  \\\n",
       "0  condition_1    1000                    12.0     0.627          0.762   \n",
       "1  condition_2    1000                    12.0     0.593          0.821   \n",
       "2  condition_3    1000                    12.0     0.710          0.735   \n",
       "\n",
       "   pct_present_exc  pct_absent_exc  \n",
       "0            0.762             0.0  \n",
       "1            0.821             0.0  \n",
       "2            0.735             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exception_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>2318</td>\n",
       "      <td>0.772667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>682</td>\n",
       "      <td>0.227333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count     share\n",
       "exception_type                 \n",
       "present          2318  0.772667\n",
       "none              682  0.227333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Majority-with-Exceptions accuracy for HUMAN trials\n",
    "# --------------------------------------------------\n",
    "# Expected columns in `human_df` (single DF or concatenation of all conditions):\n",
    "#   stimID, condition (50/50|80/20|100/0), response (1–6), TP (0|1), participantID, ...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "present_exception_threshold = 6    # set to 5 to \"leave room for 5 and 6\"\n",
    "absent_exception_threshold  = None # e.g., 1 or 2 if you want an ABSENT-side exception\n",
    "exception_priority = \"present\"     # \"present\" or \"absent\"\n",
    "tie_rule = \">\"                     # \">\" -> ties -> ABSENT; \">=\" -> ties -> PRESENT\n",
    "\n",
    "# Set this to your DataFrame name if different\n",
    "human_df = human_all  # or pd.concat([human50_50, human80_20, human100_0], ignore_index=True)\n",
    "\n",
    "# --- Sanity checks ---\n",
    "required = {\"stimID\", \"condition\", \"response\", \"TP\", \"participantID\"}\n",
    "missing = required - set(human_df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "df = human_df.copy()\n",
    "\n",
    "# Numeric response\n",
    "if not np.issubdtype(df[\"response\"].dtype, np.number):\n",
    "    df[\"response\"] = pd.to_numeric(df[\"response\"], errors=\"coerce\")\n",
    "if df[\"response\"].isna().any():\n",
    "    bad = df.loc[df[\"response\"].isna(), [\"stimID\", \"condition\", \"participantID\"]].drop_duplicates()\n",
    "    raise ValueError(\n",
    "        \"Some 'response' values could not be parsed as numbers (1–6). \"\n",
    "        f\"Examples (stimID, condition, participantID): {bad.head(5).to_dict('records')}\"\n",
    "    )\n",
    "\n",
    "# Binary decision for fallback majority\n",
    "df[\"dec_bin\"] = (df[\"response\"] >= 4).astype(int)\n",
    "\n",
    "# --- Collapse to per-participant votes to enforce uniqueness at (stimID, condition, participantID) ---\n",
    "# For exception rules:\n",
    "#   - present-exception looks for any response >= threshold  -> use per-participant MAX\n",
    "#   - absent-exception  looks for any response <= threshold  -> use per-participant MIN\n",
    "# Fallback majority uses mean of dec_bin per participant to avoid double-counting duplicates.\n",
    "per_participant = (\n",
    "    df.groupby([\"stimID\", \"condition\", \"participantID\"], as_index=False)\n",
    "      .agg(resp_max=(\"response\", \"max\"),\n",
    "           resp_min=(\"response\", \"min\"),\n",
    "           dec_bin_mean=(\"dec_bin\", \"mean\"))\n",
    ")\n",
    "\n",
    "# --- Truth per (stimID, condition) from the raw df (mode fallback) ---\n",
    "tp_per_sc = df.groupby([\"stimID\", \"condition\"])[\"TP\"]\n",
    "tp_mode = tp_per_sc.agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean()))).astype(int)\n",
    "tp_incons = tp_per_sc.nunique()\n",
    "n_bad = int((tp_incons > 1).sum())\n",
    "if n_bad > 0:\n",
    "    print(f\"Warning: {n_bad} (stimID, condition) group(s) had inconsistent TP; using per-group mode.\")\n",
    "\n",
    "# --- Group-level decision per (stimID, condition) ---\n",
    "def decide_group_pred_from_pp(g_pp: pd.DataFrame) -> pd.Series:\n",
    "    # Exception checks (from per-participant aggregates)\n",
    "    has_present_exc = (g_pp[\"resp_max\"] >= present_exception_threshold).any() if present_exception_threshold is not None else False\n",
    "    has_absent_exc  = (g_pp[\"resp_min\"] <= absent_exception_threshold).any()  if absent_exception_threshold  is not None else False\n",
    "\n",
    "    exception_type = \"none\"\n",
    "    pred = None\n",
    "\n",
    "    if has_present_exc and has_absent_exc:\n",
    "        if exception_priority == \"present\":\n",
    "            pred = 1\n",
    "            exception_type = \"present\"\n",
    "        elif exception_priority == \"absent\":\n",
    "            pred = 0\n",
    "            exception_type = \"absent\"\n",
    "        else:\n",
    "            pred = None  # unspecified -> fallback to majority\n",
    "    elif has_present_exc:\n",
    "        pred = 1\n",
    "        exception_type = \"present\"\n",
    "    elif has_absent_exc:\n",
    "        pred = 0\n",
    "        exception_type = \"absent\"\n",
    "\n",
    "    # Majority fallback (if no decisive exception)\n",
    "    if pred is None:\n",
    "        prop_present = g_pp[\"dec_bin_mean\"].mean()\n",
    "        pred = int(prop_present >= 0.5) if tie_rule == \">=\" else int(prop_present > 0.5)\n",
    "        exception_type = \"none\"\n",
    "\n",
    "    return pd.Series({\n",
    "        \"pred\": int(pred),\n",
    "        \"n_participants\": int(g_pp[\"participantID\"].nunique()),\n",
    "        \"present_exception\": bool(has_present_exc),\n",
    "        \"absent_exception\": bool(has_absent_exc),\n",
    "        \"exception_type\": exception_type,\n",
    "        \"prop_present_majority\": float(g_pp[\"dec_bin_mean\"].mean())\n",
    "    })\n",
    "\n",
    "group_decisions = (\n",
    "    per_participant.groupby([\"stimID\", \"condition\"], as_index=False)\n",
    "                   .apply(decide_group_pred_from_pp)\n",
    "                   .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Attach truth\n",
    "trial_table = group_decisions.merge(tp_mode.rename(\"truth\"), on=[\"stimID\", \"condition\"], how=\"left\")\n",
    "\n",
    "# Diagnostics & accuracy\n",
    "trial_table[\"correct\"] = (trial_table[\"pred\"] == trial_table[\"truth\"]).astype(int)\n",
    "trial_table[\"trial_key\"] = trial_table[\"condition\"].astype(str) + \"|\" + trial_table[\"stimID\"].astype(str)\n",
    "\n",
    "overall_acc = trial_table[\"correct\"].mean()\n",
    "\n",
    "by_condition = (\n",
    "    trial_table.groupby(\"condition\", as_index=False)\n",
    "               .agg(trials=(\"stimID\", \"nunique\"),\n",
    "                    participants_per_trial=(\"n_participants\", \"mean\"),\n",
    "                    accuracy=(\"correct\", \"mean\"),\n",
    "                    pct_exception=(\"exception_type\", lambda s: (s != \"none\").mean()),\n",
    "                    pct_present_exc=(\"present_exception\", \"mean\"),\n",
    "                    pct_absent_exc=(\"absent_exception\", \"mean\"))\n",
    "               .sort_values(\"condition\")\n",
    ")\n",
    "\n",
    "# Exception diagnostics (counts & shares)\n",
    "exc_counts = trial_table[\"exception_type\"].value_counts(dropna=False).rename(\"count\")\n",
    "exc_share  = (exc_counts / len(trial_table)).rename(\"share\")\n",
    "\n",
    "print(\n",
    "    f\"Majority-with-Exceptions (present≥{present_exception_threshold}\"\n",
    "    f\"{'' if absent_exception_threshold is None else f', absent≤{absent_exception_threshold}'}; \"\n",
    "    f\"priority={exception_priority}; tie='{tie_rule}')\"\n",
    ")\n",
    "print(f\"Overall accuracy: {overall_acc:.4f} | Trials (stimID×condition): {trial_table[['stimID','condition']].drop_duplicates().shape[0]}\")\n",
    "\n",
    "display(by_condition)\n",
    "display(pd.concat([exc_counts, exc_share], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9983219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging Rule (criterion: fixed=3.5, tie='>')\n",
      "Overall accuracy: 0.7277 | Trials (stimID×condition): 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>participants_per_trial</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean_conf_mean</th>\n",
       "      <th>mean_conf_std</th>\n",
       "      <th>criterion_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>3.657250</td>\n",
       "      <td>0.855552</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>3.564917</td>\n",
       "      <td>0.735121</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>1000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.805</td>\n",
       "      <td>3.477667</td>\n",
       "      <td>0.991070</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     condition  trials  participants_per_trial  accuracy  mean_conf_mean  \\\n",
       "0  condition_1    1000                    12.0     0.686        3.657250   \n",
       "1  condition_2    1000                    12.0     0.692        3.564917   \n",
       "2  condition_3    1000                    12.0     0.805        3.477667   \n",
       "\n",
       "   mean_conf_std  criterion_used  \n",
       "0       0.855552             3.5  \n",
       "1       0.735121             3.5  \n",
       "2       0.991070             3.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Averaging Rule accuracy for HUMAN trials\n",
    "# ----------------------------------------\n",
    "# Schema expected:\n",
    "#   stimID, condition (50/50|80/20|100/0), response (1–6), TP (0|1), participantID\n",
    "#\n",
    "# Rule:\n",
    "#   - Collapse to per-participant mean response for each (stimID, condition).\n",
    "#   - Compute the mean across participants (mean_conf) for each (stimID, condition).\n",
    "#   - If mean_conf > criterion → predict PRESENT; else → ABSENT (tie control via tie_rule).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Config ===\n",
    "human_df = human_all.copy()        # or pd.concat([human50_50, human80_20, human100_0], ignore_index=True)\n",
    "tie_rule = \">\"                     # \">\" = strict, \">=\" = equal means -> PRESENT\n",
    "\n",
    "# Criterion options:\n",
    "# 1) Fixed numeric threshold (e.g., 3.5)\n",
    "# 2) Adaptive:\n",
    "#       criterion_strategy = \"global_median\"        -> one global threshold\n",
    "#       criterion_strategy = \"per_condition_median\" -> threshold per condition\n",
    "criterion = 3.5\n",
    "criterion_strategy = None          # set to \"global_median\" or \"per_condition_median\" to override `criterion`\n",
    "\n",
    "# === Sanity check ===\n",
    "required = {\"stimID\", \"condition\", \"response\", \"TP\", \"participantID\"}\n",
    "missing = required - set(human_df.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "df = human_df.copy()\n",
    "\n",
    "# Convert response to numeric if needed\n",
    "if not np.issubdtype(df[\"response\"].dtype, np.number):\n",
    "    df[\"response\"] = pd.to_numeric(df[\"response\"], errors=\"coerce\")\n",
    "if df[\"response\"].isna().any():\n",
    "    bad = df.loc[df[\"response\"].isna(), [\"stimID\", \"condition\", \"participantID\"]].drop_duplicates()\n",
    "    raise ValueError(\n",
    "        \"Some 'response' values could not be parsed as numbers (1–6). \"\n",
    "        f\"Examples (stimID, condition, participantID): {bad.head(5).to_dict('records')}\"\n",
    "    )\n",
    "\n",
    "# === 1) Enforce uniqueness at (stimID, condition, participantID) via per-participant mean ===\n",
    "per_participant = (\n",
    "    df.groupby([\"stimID\", \"condition\", \"participantID\"], as_index=False)\n",
    "      .agg(resp_mean=(\"response\", \"mean\"))\n",
    ")\n",
    "\n",
    "# === 2) Trial-level (stimID, condition) mean across participants ===\n",
    "trial_mean = (\n",
    "    per_participant.groupby([\"stimID\", \"condition\"], as_index=False)\n",
    "                   .agg(mean_conf=(\"resp_mean\", \"mean\"),\n",
    "                        n_participants=(\"participantID\", \"nunique\"))\n",
    ")\n",
    "\n",
    "# Attach truth via mode (robust to accidental inconsistencies)\n",
    "tp_mode = (\n",
    "    df.groupby([\"stimID\", \"condition\"])[\"TP\"]\n",
    "      .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean())))\n",
    "      .astype(int)\n",
    "      .rename(\"truth\")\n",
    "      .reset_index()\n",
    ")\n",
    "trial_mean = trial_mean.merge(tp_mode, on=[\"stimID\", \"condition\"], how=\"left\")\n",
    "\n",
    "# === 3) Choose criterion (fixed or adaptive) ===\n",
    "if criterion_strategy is None:\n",
    "    # Fixed numeric threshold for all conditions\n",
    "    trial_mean[\"criterion\"] = float(criterion)\n",
    "elif criterion_strategy == \"global_median\":\n",
    "    # One global threshold based on trial-level mean_conf\n",
    "    global_thresh = float(trial_mean[\"mean_conf\"].median())\n",
    "    trial_mean[\"criterion\"] = global_thresh\n",
    "elif criterion_strategy == \"per_condition_median\":\n",
    "    # Per-condition thresholds based on trial-level mean_conf within each condition\n",
    "    cond_thresh = (\n",
    "        trial_mean.groupby(\"condition\")[\"mean_conf\"].median().rename(\"criterion\").reset_index()\n",
    "    )\n",
    "    trial_mean = trial_mean.merge(cond_thresh, on=\"condition\", how=\"left\")\n",
    "else:\n",
    "    raise ValueError(\"criterion_strategy must be None, 'global_median', or 'per_condition_median'.\")\n",
    "\n",
    "# === 4) Apply Averaging Rule decision ===\n",
    "if tie_rule == \">=\":\n",
    "    trial_mean[\"pred\"] = (trial_mean[\"mean_conf\"] >= trial_mean[\"criterion\"]).astype(int)\n",
    "elif tie_rule == \">\":\n",
    "    trial_mean[\"pred\"] = (trial_mean[\"mean_conf\"] > trial_mean[\"criterion\"]).astype(int)\n",
    "else:\n",
    "    raise ValueError(\"tie_rule must be '>' or '>='.\")\n",
    "\n",
    "# === 5) Evaluate accuracy & summarize ===\n",
    "trial_mean[\"correct\"] = (trial_mean[\"pred\"] == trial_mean[\"truth\"]).astype(int)\n",
    "trial_mean[\"trial_key\"] = trial_mean[\"condition\"].astype(str) + \"|\" + trial_mean[\"stimID\"].astype(str)\n",
    "\n",
    "overall_acc = trial_mean[\"correct\"].mean()\n",
    "\n",
    "by_condition = (\n",
    "    trial_mean.groupby(\"condition\", as_index=False)\n",
    "              .agg(trials=(\"stimID\", \"nunique\"),\n",
    "                   participants_per_trial=(\"n_participants\", \"mean\"),\n",
    "                   accuracy=(\"correct\", \"mean\"),\n",
    "                   mean_conf_mean=(\"mean_conf\", \"mean\"),\n",
    "                   mean_conf_std=(\"mean_conf\", \"std\"),\n",
    "                   criterion_used=(\"criterion\", \"mean\"))\n",
    "              .sort_values(\"condition\")\n",
    ")\n",
    "\n",
    "# === Output ===\n",
    "crit_msg = f\"fixed={criterion}\" if criterion_strategy is None else f\"adaptive={criterion_strategy}\"\n",
    "print(f\"Averaging Rule (criterion: {crit_msg}, tie='{tie_rule}')\")\n",
    "print(f\"Overall accuracy: {overall_acc:.4f} | Trials (stimID×condition): {trial_mean[['stimID','condition']].drop_duplicates().shape[0]}\")\n",
    "\n",
    "display(by_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc99e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WLC fit complete | Trials (stimID×condition): 3000 | Participants: 12 | rank(Σ)=12 | λ=1e-06\n",
      "Best criterion (tie='>'): -0.0904937\n",
      "Overall accuracy: 0.8060\n",
      "\n",
      "Top weights (head):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>weight</th>\n",
       "      <th>Delta_mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KM</td>\n",
       "      <td>0.462318</td>\n",
       "      <td>1.709333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JH</td>\n",
       "      <td>0.243044</td>\n",
       "      <td>1.290667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KZ</td>\n",
       "      <td>0.190095</td>\n",
       "      <td>1.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AG</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>1.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UR</td>\n",
       "      <td>0.132811</td>\n",
       "      <td>1.127333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SA</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.647333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GS</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.202667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AZ</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.467333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AW</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.779333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HG</td>\n",
       "      <td>-0.009786</td>\n",
       "      <td>1.588000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID    weight  Delta_mu\n",
       "0            KM  0.462318  1.709333\n",
       "1            JH  0.243044  1.290667\n",
       "2            KZ  0.190095  1.006667\n",
       "3            AG  0.168199  1.514000\n",
       "4            UR  0.132811  1.127333\n",
       "5            SA  0.070051  0.647333\n",
       "6            GS  0.048714  0.202667\n",
       "7            AZ  0.015612  0.467333\n",
       "8            AW  0.011665  0.779333\n",
       "9            HG -0.009786  1.588000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>D_mean</th>\n",
       "      <th>D_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>condition_1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>1.144754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_2</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.759</td>\n",
       "      <td>-0.059705</td>\n",
       "      <td>1.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>condition_3</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.008858</td>\n",
       "      <td>1.553994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     condition  trials  accuracy    D_mean     D_std\n",
       "0  condition_1    1000     0.784  0.050847  1.144754\n",
       "1  condition_2    1000     0.759 -0.059705  1.162920\n",
       "2  condition_3    1000     0.875  0.008858  1.553994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Weighted Linear Combination (WLC) rule for HUMAN trials\n",
    "# -------------------------------------------------------\n",
    "# Expected columns in HUMAN_DF:\n",
    "#   stimID, participantID, response (1–6), TP (0/1), condition\n",
    "#\n",
    "# Uniqueness & aggregation:\n",
    "#   - Raw uniqueness enforced at (stimID, condition, participantID) by averaging duplicates.\n",
    "#   - Trial rows are (stimID, condition) so each stimID yields 3 trials (one per condition).\n",
    "#\n",
    "# Method:\n",
    "#   1) Build trial x participant matrix of responses.\n",
    "#   2) Compute participant-wise Δμ = mean(response|TP=1) - mean(response|TP=0).\n",
    "#   3) Estimate covariance Σ across participants (responses centered by participant).\n",
    "#   4) Compute weights w = (Σ + λI)^(-1) Δμ  (ridge-regularized).\n",
    "#   5) Decision variable per trial: D = X_centered @ w.\n",
    "#   6) Sweep a scalar criterion to maximize accuracy (tie behavior via TIE_RULE).\n",
    "#   7) Accuracy overall and by condition; return diagnostics.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======== CONFIG ========\n",
    "HUMAN_DF = human_all.copy()   # or pd.concat([human50_50, human80_20, human100_0], ignore_index=True)\n",
    "CENTER_BY_PARTICIPANT = True  # center each participant's ratings (remove response bias)\n",
    "STANDARDIZE = False           # optional z-score per participant (usually not needed for WLC)\n",
    "REG_LAMBDA = 1e-6             # ridge regularization strength added to diag(Σ)\n",
    "TIE_RULE = \">\"                # '>' -> equal-to-threshold -> absent ; '>=' -> equal -> present\n",
    "# ========================\n",
    "\n",
    "# --- Sanity checks ---\n",
    "req = {\"stimID\", \"participantID\", \"response\", \"TP\", \"condition\"}\n",
    "missing = req - set(HUMAN_DF.columns)\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "df = HUMAN_DF.copy()\n",
    "\n",
    "# Coerce dtypes\n",
    "df[\"TP\"] = pd.to_numeric(df[\"TP\"], errors=\"coerce\").astype(int)\n",
    "df[\"response\"] = pd.to_numeric(df[\"response\"], errors=\"coerce\")\n",
    "if df[\"response\"].isna().any():\n",
    "    bad_n = int(df[\"response\"].isna().sum())\n",
    "    bad = df.loc[df[\"response\"].isna(), [\"stimID\", \"condition\", \"participantID\"]].drop_duplicates()\n",
    "    raise ValueError(\n",
    "        f\"{bad_n} response value(s) could not be parsed as numeric. \"\n",
    "        f\"Examples: {bad.head(5).to_dict('records')}\"\n",
    "    )\n",
    "\n",
    "# --- Enforce raw uniqueness at (stimID, condition, participantID) ---\n",
    "# If duplicates exist for the same participant & (stimID, condition), average them.\n",
    "df_uni = (\n",
    "    df.groupby([\"stimID\", \"condition\", \"participantID\"], as_index=False)\n",
    "      .agg(response=(\"response\", \"mean\"))\n",
    ")\n",
    "\n",
    "# --- 1) Trial x participant matrix (responses) at (stimID, condition) ---\n",
    "R = df_uni.pivot_table(\n",
    "        index=[\"stimID\", \"condition\"],\n",
    "        columns=\"participantID\",\n",
    "        values=\"response\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).sort_index()\n",
    "\n",
    "# --- Truth per (stimID, condition) from raw df (mode fallback) ---\n",
    "truth_sc = (\n",
    "    df.groupby([\"stimID\", \"condition\"])[\"TP\"]\n",
    "      .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean())))\n",
    "      .astype(int)\n",
    "      .reindex(R.index)\n",
    ")\n",
    "\n",
    "# --- 2) Participant discrimination Δμ ---\n",
    "# Compute per-participant means split by TP on the raw df (not R), then difference.\n",
    "means_by_tp = (\n",
    "    df.groupby([\"participantID\", \"TP\"])[\"response\"]\n",
    "      .mean()\n",
    "      .unstack(\"TP\")  # columns {0,1}\n",
    ")\n",
    "if 0 not in means_by_tp.columns: means_by_tp[0] = np.nan\n",
    "if 1 not in means_by_tp.columns: means_by_tp[1] = np.nan\n",
    "Delta_mu = (means_by_tp[1] - means_by_tp[0]).fillna(0.0)\n",
    "\n",
    "# Align Δμ to R's participant order\n",
    "Delta_mu = Delta_mu.reindex(R.columns).fillna(0.0).to_numpy(dtype=float)  # shape (P,)\n",
    "\n",
    "# --- 3) Prepare data matrix for covariance ---\n",
    "X = R.copy()\n",
    "\n",
    "# Center / standardize per participant (column-wise)\n",
    "col_means = X.mean(axis=0, skipna=True)\n",
    "if CENTER_BY_PARTICIPANT:\n",
    "    X = X.subtract(col_means, axis=1)\n",
    "\n",
    "if STANDARDIZE:\n",
    "    col_stds = X.std(axis=0, ddof=1, skipna=True).replace(0, np.nan)\n",
    "    X = X.divide(col_stds, axis=1)\n",
    "\n",
    "# Fill remaining NaNs with 0 (participant-at-mean after centering)\n",
    "X = X.fillna(0.0)\n",
    "\n",
    "# Convert to numpy (trials x participants)\n",
    "X_np = X.to_numpy(dtype=float)     # shape (N, P)\n",
    "N, P = X_np.shape\n",
    "\n",
    "# --- 4) Covariance Σ and weights w ---\n",
    "Sigma = np.cov(X_np, rowvar=False, ddof=1)  # (P, P)\n",
    "Sigma_reg = Sigma + REG_LAMBDA * np.eye(P)\n",
    "\n",
    "try:\n",
    "    w = np.linalg.solve(Sigma_reg, Delta_mu)   # (P,)\n",
    "except np.linalg.LinAlgError:\n",
    "    w = np.linalg.pinv(Sigma_reg) @ Delta_mu\n",
    "\n",
    "# --- 5) Decision variable per trial ---\n",
    "D = X_np @ w  # shape (N,)\n",
    "\n",
    "# --- 6) Fit a scalar criterion by sweeping to maximize accuracy ---\n",
    "y = truth_sc.to_numpy()\n",
    "D_sorted = np.unique(D)\n",
    "\n",
    "if len(D_sorted) == 1:\n",
    "    crit_best = D_sorted[0]\n",
    "    pred = np.full_like(D, fill_value=int(y.mean() >= 0.5))\n",
    "else:\n",
    "    mids = (D_sorted[:-1] + D_sorted[1:]) / 2.0\n",
    "    cands = np.concatenate(([-np.inf], mids, [np.inf]))\n",
    "\n",
    "    best_acc, crit_best, pred = -1.0, None, None\n",
    "    for c in cands:\n",
    "        if TIE_RULE == \">=\":\n",
    "            p = (D >= c).astype(int)\n",
    "        else:\n",
    "            p = (D >  c).astype(int)\n",
    "        acc = (p == y).mean()\n",
    "        if acc > best_acc:\n",
    "            best_acc, crit_best, pred = acc, c, p\n",
    "\n",
    "# --- Trial table (index is (stimID, condition)) ---\n",
    "trial_table = (\n",
    "    pd.DataFrame({\n",
    "        \"D\": D,\n",
    "        \"pred\": pred.astype(int),\n",
    "        \"truth\": y,\n",
    "    }, index=X.index)\n",
    "    .reset_index()\n",
    "    .assign(correct=lambda t: (t[\"pred\"] == t[\"truth\"]).astype(int))\n",
    ")\n",
    "\n",
    "trial_table[\"trial_key\"] = trial_table[\"condition\"].astype(str) + \"|\" + trial_table[\"stimID\"].astype(str)\n",
    "\n",
    "# --- Summaries ---\n",
    "overall_acc = trial_table[\"correct\"].mean()\n",
    "by_condition = (\n",
    "    trial_table.groupby(\"condition\", as_index=False)\n",
    "               .agg(trials=(\"stimID\", \"nunique\"),\n",
    "                    accuracy=(\"correct\", \"mean\"),\n",
    "                    D_mean=(\"D\", \"mean\"),\n",
    "                    D_std=(\"D\", \"std\"))\n",
    "               .sort_values(\"condition\")\n",
    ")\n",
    "\n",
    "# --- Diagnostics (weights & contributions) ---\n",
    "Delta_mu_series = (\n",
    "    pd.Series(Delta_mu, index=R.columns, name=\"Delta_mu\")\n",
    ")\n",
    "\n",
    "weights_df = (\n",
    "    pd.DataFrame({\"weight\": w}, index=R.columns)  # index = participantID\n",
    "      .join(Delta_mu_series, how=\"left\")\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"participantID\"})\n",
    "      .sort_values(\"weight\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "rank_sigma = np.linalg.matrix_rank(Sigma)\n",
    "print(f\"WLC fit complete | Trials (stimID×condition): {N} | Participants: {P} | rank(Σ)={rank_sigma} | λ={REG_LAMBDA:g}\")\n",
    "print(f\"Best criterion (tie='{TIE_RULE}'): {crit_best:.6g}\")\n",
    "print(f\"Overall accuracy: {overall_acc:.4f}\")\n",
    "\n",
    "print(\"\\nTop weights (head):\")\n",
    "display(weights_df.head(10))\n",
    "display(by_condition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexwisdom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
