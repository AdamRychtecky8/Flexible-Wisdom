{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90679137",
   "metadata": {},
   "source": [
    "# Flexible Collective Wisdom — SNR Exploration Notebook\n",
    "\n",
    "**Purpose.** Compute and compare alternative Signal-to-Noise Ratio (SNR) definitions for a covert-attention dataset, then select one SNR for downstream accuracy/ROC analyses and human-vs-LLM comparisons.\n",
    "\n",
    "**Expected columns:** `stimID, condition (50_50|80_20|100_0), response (1–6), side_selected (1|2), cue_points (1|2), line1_angle (deg), line2_angle (deg), valid_cue (0|1), TP (0|1), participantID`.\n",
    "\n",
    "**Workflow overview**\n",
    "1. Load & preprocess\n",
    "2. Estimate noise scale (σ) from TP=0 per participant×side\n",
    "3. Compute SNR candidates (trial-level & condition-level)\n",
    "4. Diagnostics and cross-validated predictive validity\n",
    "5. Plots & selection\n",
    "6. Export winner recipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ee4efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss, brier_score_loss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n",
    "\n",
    "# === Config ===\n",
    "DATA_PATH = Path('data/human_trials.csv')  # <-- change to your path\n",
    "SAVE_DIR = Path('outputs/snr_eval')\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf140bf",
   "metadata": {},
   "source": [
    "## 1. Load & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ea9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    expected_cols = ['stimID','condition','response','side_selected','cue_points',\n",
    "                     'line1_angle','line2_angle','valid_cue','TP','participantID']\n",
    "    missing = [c for c in expected_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns: {missing}\")\n",
    "    df['yes'] = (df['response'] >= 4).astype(int)\n",
    "    df['correct'] = (df['yes'] == df['TP']).astype(int)\n",
    "    df['participantID'] = df['participantID'].astype(str)\n",
    "    df['condition'] = df['condition'].astype(str)\n",
    "    for c in ['side_selected','cue_points','valid_cue','TP']:\n",
    "        df[c] = df[c].astype(int)\n",
    "    for c in ['line1_angle','line2_angle']:\n",
    "        df[c] = df[c].astype(float)\n",
    "    return df\n",
    "\n",
    "df = load_data(DATA_PATH)\n",
    "print(df.head(3))\n",
    "print(df.condition.value_counts(dropna=False))\n",
    "print('N trials:', len(df), 'N participants:', df.participantID.nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b909023",
   "metadata": {},
   "source": [
    "## 2. Estimate noise (σ) from TP=0 per participant×side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_sigma(x: np.ndarray) -> float:\n",
    "    mad = np.median(np.abs(x - np.median(x)))\n",
    "    if mad == 0:\n",
    "        s = np.std(x, ddof=1) if x.size > 1 else 1.0\n",
    "        return float(s if s > 0 else 1.0)\n",
    "    return float(1.4826 * mad)\n",
    "\n",
    "def estimate_sigma(df: pd.DataFrame, method: str = 'MAD') -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for pid, gpid in df[df['TP']==0].groupby('participantID'):\n",
    "        for side in [1,2]:\n",
    "            ang = gpid['line1_angle'] if side==1 else gpid['line2_angle']\n",
    "            ang = ang.to_numpy()\n",
    "            if method.upper() == 'MAD':\n",
    "                sigma = robust_sigma(ang)\n",
    "            else:\n",
    "                sigma = float(np.std(ang, ddof=1)) if ang.size>1 else 1.0\n",
    "                if sigma <= 0: sigma = 1.0\n",
    "            rows.append({'participantID': pid, 'side': side, 'sigma': sigma, 'n0': int(len(ang))})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "sigma_tbl = estimate_sigma(df, method='MAD')\n",
    "print(sigma_tbl.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6041cd",
   "metadata": {},
   "source": [
    "## 3. Target tilt per trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_tilt(row) -> float:\n",
    "    if row['TP'] == 1:\n",
    "        target_side = row['cue_points'] if row['valid_cue']==1 else (1 if row['cue_points']==2 else 2)\n",
    "        tilt = abs(row['line1_angle']) if target_side==1 else abs(row['line2_angle'])\n",
    "        return float(tilt)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "df['target_tilt_abs'] = df.apply(target_tilt, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aab075",
   "metadata": {},
   "source": [
    "## 4. Compute SNR candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_sigma(df: pd.DataFrame, sigma_tbl: pd.DataFrame) -> pd.DataFrame:\n",
    "    sig1 = sigma_tbl[sigma_tbl['side']==1].rename(columns={'sigma':'sigma1','n0':'n01'})[['participantID','sigma1','n01']]\n",
    "    sig2 = sigma_tbl[sigma_tbl['side']==2].rename(columns={'sigma':'sigma2','n0':'n02'})[['participantID','sigma2','n02']]\n",
    "    out = df.merge(sig1, on='participantID', how='left').merge(sig2, on='participantID', how='left')\n",
    "    for c in ['sigma1','sigma2']:\n",
    "        out[c] = out[c].fillna(out[c].median())\n",
    "        out[c] = out[c].replace(0, out[c].median())\n",
    "    return out\n",
    "\n",
    "df = attach_sigma(df, sigma_tbl)\n",
    "\n",
    "# Candidate 1: Angle-based\n",
    "df['SNR_angle'] = df['target_tilt_abs'] / np.where(df['cue_points']==1, df['sigma1'], df['sigma2'])\n",
    "\n",
    "# Candidate 2: Side-max\n",
    "df['SNR_side_max'] = np.maximum(abs(df['line1_angle']), abs(df['line2_angle'])) / df[['sigma1','sigma2']].mean(axis=1)\n",
    "\n",
    "# Candidate 3: Cue-aware weighted\n",
    "w = np.where(df['valid_cue']==1, 1.0, 0.5)\n",
    "tilt_cued = np.where(df['cue_points']==1, abs(df['line1_angle']), abs(df['line2_angle']))\n",
    "df['SNR_cue_weighted'] = (w * tilt_cued) / np.where(df['cue_points']==1, df['sigma1'], df['sigma2'])\n",
    "\n",
    "# Candidate 4: Condition ordinal proxy\n",
    "cond_map = {'50_50': 1, '80_20': 2, '100_0': 3}\n",
    "df['SNR_cond_ord'] = df['condition'].map(cond_map).astype(float)\n",
    "\n",
    "print(df[['SNR_angle','SNR_side_max','SNR_cue_weighted','SNR_cond_ord']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8782b5d6",
   "metadata": {},
   "source": [
    "## 5. Empirical SNR per participant×condition (d′) and hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprime_from_rates(H, F):\n",
    "    # Loglinear correction to avoid inf/NaN\n",
    "    eps = 1e-6\n",
    "    Hc = min(max(H, eps), 1-eps)\n",
    "    Fc = min(max(F, eps), 1-eps)\n",
    "    from math import sqrt\n",
    "    from scipy.stats import norm\n",
    "    z = norm.ppf\n",
    "    return float(z(Hc) - z(Fc))\n",
    "\n",
    "def empirical_dprime_table(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for (pid, cond), g in df.groupby(['participantID','condition']):\n",
    "        if (g['TP']==1).any() and (g['TP']==0).any():\n",
    "            H = g.loc[g['TP']==1, 'yes'].mean()\n",
    "            F = g.loc[g['TP']==0, 'yes'].mean()\n",
    "            try:\n",
    "                dp = dprime_from_rates(H, F)\n",
    "            except Exception:\n",
    "                dp = np.nan\n",
    "        else:\n",
    "            dp = np.nan\n",
    "        rows.append({'participantID': pid, 'condition': cond, 'dprime_emp': dp})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "try:\n",
    "    dprime_tbl = empirical_dprime_table(df)\n",
    "    df = df.merge(dprime_tbl, on=['participantID','condition'], how='left')\n",
    "    df['SNR_hybrid_emp'] = df['dprime_emp']\n",
    "except Exception as e:\n",
    "    print('Empirical d\\u2032 step skipped (install scipy). Error:', e)\n",
    "    df['dprime_emp'] = np.nan\n",
    "    df['SNR_hybrid_emp'] = np.nan\n",
    "\n",
    "print(df[['participantID','condition','dprime_emp']].drop_duplicates().head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03729fbf",
   "metadata": {},
   "source": [
    "## 6. Optional: within-participant z-scoring of SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d579eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_COLS = ['SNR_angle','SNR_side_max','SNR_cue_weighted','SNR_cond_ord','SNR_hybrid_emp']\n",
    "\n",
    "def zscore_within(df, cols, by='participantID'):\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        def _z(x):\n",
    "            s = x.std(ddof=1)\n",
    "            return (x - x.mean()) / (s if s>0 else 1.0)\n",
    "        out[c + '_z'] = out.groupby(by)[c].transform(_z)\n",
    "    return out\n",
    "\n",
    "dfz = zscore_within(df, SNR_COLS)\n",
    "print(dfz[[c for c in dfz.columns if c.endswith('_z')]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d53128",
   "metadata": {},
   "source": [
    "## 7. Diagnostics: monotonicity, separation, calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612c64a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_and_acc(df: pd.DataFrame, col: str, n_bins: int = 5) -> pd.DataFrame:\n",
    "    g = df.copy()\n",
    "    g['bin'] = pd.qcut(g[col], q=n_bins, duplicates='drop')\n",
    "    out = g.groupby('bin').agg(acc=('correct','mean'),\n",
    "                               yes_rate=('yes','mean'),\n",
    "                               n=('correct','size'),\n",
    "                               snr_mean=(col,'mean')).reset_index()\n",
    "    return out\n",
    "\n",
    "def separation_stats(df: pd.DataFrame, col: str) -> Dict[str,float]:\n",
    "    from scipy.stats import ks_2samp\n",
    "    a = df.loc[df['TP']==1, col].dropna()\n",
    "    b = df.loc[df['TP']==0, col].dropna()\n",
    "    if len(a)<2 or len(b)<2:\n",
    "        return {'cohen_d': np.nan, 'ks': np.nan}\n",
    "    d = (a.mean()-b.mean()) / np.sqrt(0.5*(a.var(ddof=1)+b.var(ddof=1)))\n",
    "    ks = ks_2samp(a, b).statistic\n",
    "    return {'cohen_d': float(d), 'ks': float(ks)}\n",
    "\n",
    "def plot_accuracy_vs_snr(df: pd.DataFrame, col: str, n_bins: int = 5):\n",
    "    b = bin_and_acc(df, col, n_bins=n_bins)\n",
    "    plt.figure()\n",
    "    plt.errorbar(b['snr_mean'], b['acc'], yerr=np.sqrt(b['acc']*(1-b['acc'])/b['n']), fmt='o-')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Proportion correct')\n",
    "    plt.title(f'Accuracy vs {col} (bin means \\u00B1 SE)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_density_tp(df: pd.DataFrame, col: str):\n",
    "    plt.figure()\n",
    "    df.loc[df['TP']==1, col].dropna().plot(kind='hist', bins=30, alpha=0.5, label='TP=1')\n",
    "    df.loc[df['TP']==0, col].dropna().plot(kind='hist', bins=30, alpha=0.5, label='TP=0')\n",
    "    plt.legend()\n",
    "    plt.xlabel(col)\n",
    "    plt.title(f'Density overlay by TP for {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939abd2",
   "metadata": {},
   "source": [
    "## 8. Predictive validity (5× CV stratified by participant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52391618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def cv_metrics_for_snr(df: pd.DataFrame, col: str, k: int = 5) -> Dict[str,float]:\n",
    "    X = df[[col,'valid_cue']].copy()\n",
    "    X['condition'] = df['condition']\n",
    "    X['participantID'] = df['participantID']\n",
    "    y = df['correct'].astype(int).values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
    "    part_labels = df['participantID'].astype('category').cat.codes.values\n",
    "\n",
    "    aucs, lls, brs = [], [], []\n",
    "    for tr, te in skf.split(np.zeros_like(part_labels), part_labels):\n",
    "        Xtr, Xte = X.iloc[tr], X.iloc[te]\n",
    "        ytr, yte = y[tr], y[te]\n",
    "\n",
    "        num = [col, 'valid_cue']\n",
    "        cat = ['condition','participantID']\n",
    "        pre = ColumnTransformer([\n",
    "            ('num', StandardScaler(), num),\n",
    "            ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat)\n",
    "        ])\n",
    "\n",
    "        clf = Pipeline([('pre', pre),\n",
    "                        ('logit', LogisticRegression(max_iter=200, solver='lbfgs'))])\n",
    "        clf.fit(Xtr, ytr)\n",
    "        p = clf.predict_proba(Xte)[:,1]\n",
    "\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(yte, p))\n",
    "        except Exception:\n",
    "            aucs.append(np.nan)\n",
    "        lls.append(log_loss(yte, p, labels=[0,1]))\n",
    "        brs.append(brier_score_loss(yte, p))\n",
    "\n",
    "    return {'CV_AUC': float(np.nanmean(aucs)),\n",
    "            'CV_LogLoss': float(np.mean(lls)),\n",
    "            'CV_Brier': float(np.mean(brs))}\n",
    "\n",
    "metrics_rows = []\n",
    "for c in ['SNR_angle','SNR_side_max','SNR_cue_weighted','SNR_cond_ord','SNR_hybrid_emp']:\n",
    "    try:\n",
    "        m = cv_metrics_for_snr(df, c)\n",
    "        m['SNR'] = c\n",
    "        metrics_rows.append(m)\n",
    "    except Exception as e:\n",
    "        metrics_rows.append({'SNR': c, 'CV_AUC': np.nan, 'CV_LogLoss': np.nan, 'CV_Brier': np.nan})\n",
    "\n",
    "metrics = pd.DataFrame(metrics_rows).set_index('SNR').sort_values('CV_LogLoss')\n",
    "print(metrics)\n",
    "metrics.to_csv(SAVE_DIR / 'cv_metrics.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f35c88",
   "metadata": {},
   "source": [
    "## 9. Calibration (reliability curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reliability_curve(y_true, y_prob, n_bins=10):\n",
    "    dfc = pd.DataFrame({'y': y_true, 'p': y_prob}).dropna()\n",
    "    dfc['bin'] = pd.qcut(dfc['p'], q=n_bins, duplicates='drop')\n",
    "    out = dfc.groupby('bin').agg(p_hat=('p','mean'), y_bar=('y','mean'), n=('y','size')).reset_index()\n",
    "    return out\n",
    "\n",
    "def plot_reliability_curve(out: pd.DataFrame):\n",
    "    plt.figure()\n",
    "    plt.plot(out['p_hat'], out['y_bar'], marker='o')\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.xlabel('Predicted accuracy')\n",
    "    plt.ylabel('Observed accuracy')\n",
    "    plt.title('Reliability curve')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: choose best by LogLoss and plot reliability\n",
    "best = metrics.sort_values('CV_LogLoss').index[0]\n",
    "print('Best by LogLoss:', best)\n",
    "\n",
    "X = df[[best,'valid_cue']].copy()\n",
    "X['condition'] = df['condition']\n",
    "X['participantID'] = df['participantID']\n",
    "y = df['correct'].astype(int).values\n",
    "\n",
    "num = [best, 'valid_cue']\n",
    "cat = ['condition','participantID']\n",
    "pre = ColumnTransformer([('num', StandardScaler(), num),\n",
    "                         ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat)])\n",
    "clf = Pipeline([('pre', pre), ('logit', LogisticRegression(max_iter=200, solver='lbfgs'))])\n",
    "clf.fit(X, y)\n",
    "p_full = clf.predict_proba(X)[:,1]\n",
    "\n",
    "rel = reliability_curve(y, p_full, n_bins=10)\n",
    "print(rel)\n",
    "plot_reliability_curve(rel)\n",
    "rel.to_csv(SAVE_DIR / f'reliability_{best}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520191b",
   "metadata": {},
   "source": [
    "## 10. Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c62a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['SNR_angle','SNR_side_max','SNR_cue_weighted','SNR_cond_ord','SNR_hybrid_emp']:\n",
    "    try:\n",
    "        plot_accuracy_vs_snr(df, c, n_bins=5)\n",
    "        plot_density_tp(df, c)\n",
    "    except Exception as e:\n",
    "        print('Plotting issue for', c, '->', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfbcf1",
   "metadata": {},
   "source": [
    "## 11. Export: Winner SNR recipe (for pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92efc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = metrics.sort_values('CV_LogLoss').index[0]\n",
    "recipe = (\n",
    "    'Recommended SNR: ' + winner + '\\n\\n'\n",
    "    'Computation:\\n'\n",
    "    '1) Estimate sigma per participant×side from TP=0 trials using MAD×1.4826 (fallback to std if MAD=0).\\n'\n",
    "    '2) For each trial, compute:\\n'\n",
    "    '   - target_tilt_abs: if TP=1, absolute tilt of the actual target side (cue side if valid, opposite if invalid);\\n'\n",
    "    '                      if TP=0, 0 (for angle-based) or max(|line1|,|line2|) (for side-max).\\n'\n",
    "    '3) SNR candidates:\\n'\n",
    "    '   - SNR_angle = target_tilt_abs / sigma_target_side\\n'\n",
    "    '   - SNR_side_max = max(|line1|,|line2|) / mean(sigma1, sigma2)\\n'\n",
    "    '   - SNR_cue_weighted = w * tilt_cued / sigma_cued, with w=1 if valid_cue else 0.5\\n'\n",
    "    \"   - SNR_cond_ord = map {'50_50':1, '80_20':2, '100_0':3}\\n\"\n",
    "    '   - SNR_hybrid_emp = d′(participant×condition) assigned to trials\\n'\n",
    "    '4) (Optional) z-score SNR within participant.\\n'\n",
    ")\n",
    "path = Path('outputs/snr_eval')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "(path / 'winner_snr_recipe.txt').write_text(recipe, encoding='utf-8')\n",
    "print(recipe)\n",
    "print('Saved to:', path / 'winner_snr_recipe.txt')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
