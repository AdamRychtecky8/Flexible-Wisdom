{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230ffc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/AdamR/OneDrive/UCSB/VIU/HonorsThesis/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd() / \"notebooks\"))  # so we can import _utils from notebooks/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from _utils import get_data_dir\n",
    "\n",
    "DATA_DIR = get_data_dir()\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bdd622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded Gemini data for 50_50: C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\data\\50_50\\angle_estimations\\gemini-2.5-pro.csv\n",
      "✅ Loaded Gemini data for 80_20: C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\data\\80_20\\angle_estimations\\gemini-2.5-pro.csv\n",
      "✅ Loaded Gemini data for 100_0: C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\data\\100_0\\angle_estimations\\gemini-2.5-pro.csv\n",
      "\n",
      "Summary of loaded Gemini datasets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>n_rows</th>\n",
       "      <th>n_cols</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50_50</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80_20</td>\n",
       "      <td>1000</td>\n",
       "      <td>9</td>\n",
       "      <td>C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  n_rows  n_cols                                               path\n",
       "0     100_0    1000       9  C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\...\n",
       "1     50_50    1000       9  C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\...\n",
       "2     80_20    1000       9  C:\\Users\\AdamR\\OneDrive\\UCSB\\VIU\\HonorsThesis\\..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Load Gemini-2.5-Pro angle estimation CSVs for 50_50, 80_20, and 100_0 ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = DATA_DIR  # <-- ensure DATA_DIR points to your project root\n",
    "FOLDERS = [\"50_50\", \"80_20\", \"100_0\"]\n",
    "SUBPATH = \"angle_estimations/gemini-2.5-pro.csv\"\n",
    "\n",
    "def safe_read_csv(path: Path, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Robust CSV reader with fallback parsing.\"\"\"\n",
    "    defaults = dict(low_memory=False, encoding_errors=\"ignore\")\n",
    "    defaults.update(kwargs)\n",
    "    try:\n",
    "        return pd.read_csv(path, **defaults)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, engine=\"python\", sep=None, **defaults)\n",
    "\n",
    "def load_gemini_dataset(folder: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load only the Gemini-2.5-Pro CSV from angle_estimations/ subfolder.\"\"\"\n",
    "    gemini_path = folder / SUBPATH\n",
    "    if not gemini_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing {SUBPATH} in {folder}\")\n",
    "    df = safe_read_csv(gemini_path)\n",
    "    df[\"condition\"] = folder.name  # tag condition (50_50, 80_20, 100_0)\n",
    "    return df, gemini_path\n",
    "\n",
    "# === Main loading loop ===\n",
    "datasets = {}\n",
    "records = []\n",
    "\n",
    "for name in FOLDERS:\n",
    "    folder = ROOT / name\n",
    "    if not folder.exists():\n",
    "        print(f\"⚠️ Warning: Folder '{name}' not found under {ROOT}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df, path = load_gemini_dataset(folder)\n",
    "        datasets[name] = df\n",
    "        records.append({\n",
    "            \"condition\": name,\n",
    "            \"n_rows\": len(df),\n",
    "            \"n_cols\": df.shape[1],\n",
    "            \"path\": str(path.resolve())\n",
    "        })\n",
    "        print(f\"✅ Loaded Gemini data for {name}: {path}\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"⚠️\", e)\n",
    "\n",
    "# === Summary table ===\n",
    "gemini_index = pd.DataFrame.from_records(records).sort_values(\"condition\").reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57a12ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_columns(csv_path):\n",
    "    \"\"\"\n",
    "    Return a list of column names from a CSV file.\n",
    "    Accepts either a string/Path to a file or a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(csv_path, pd.DataFrame):\n",
    "        return list(csv_path.columns)\n",
    "    \n",
    "    csv_path = Path(csv_path)\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {csv_path}\")\n",
    "    \n",
    "    # Read only the header row\n",
    "    df = pd.read_csv(csv_path, nrows=0, encoding_errors=\"ignore\")\n",
    "    return list(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab6fc0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>side_selected</th>\n",
       "      <th>cue_points</th>\n",
       "      <th>line1_angle</th>\n",
       "      <th>line2_angle</th>\n",
       "      <th>valid_cue</th>\n",
       "      <th>TP</th>\n",
       "      <th>GPT_response</th>\n",
       "      <th>condition</th>\n",
       "      <th>est_angle_1</th>\n",
       "      <th>est_angle_2</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>1.921956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-14.8, -1.2, present</td>\n",
       "      <td>100_0</td>\n",
       "      <td>-14.8</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-15.2, 1.0, present</td>\n",
       "      <td>100_0</td>\n",
       "      <td>-15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>6.508956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>16.5, 4.5, present</td>\n",
       "      <td>100_0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.775056</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6.1, 16.0, present</td>\n",
       "      <td>100_0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>19.885165</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1, 18.2, present</td>\n",
       "      <td>100_0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  side_selected  cue_points  line1_angle  line2_angle  valid_cue  \\\n",
       "0       100              1           1    14.314827     1.921956       True   \n",
       "1       845              1           1    15.054317     4.222230       True   \n",
       "2       245              1           1    14.314827     6.508956       True   \n",
       "3        72              2           2     8.775056    15.054317       True   \n",
       "4       469              2           2     4.222230    19.885165       True   \n",
       "\n",
       "     TP          GPT_response condition  est_angle_1  est_angle_2 decision  \n",
       "0  True  -14.8, -1.2, present     100_0        -14.8         -1.2  present  \n",
       "1  True   -15.2, 1.0, present     100_0        -15.2          1.0  present  \n",
       "2  True    16.5, 4.5, present     100_0         16.5          4.5  present  \n",
       "3  True    6.1, 16.0, present     100_0          6.1         16.0  present  \n",
       "4  True    4.1, 18.2, present     100_0          4.1         18.2  present  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Parse Gemini GPT_response into separate columns for each condition ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_gpt_response(resp):\n",
    "    \"\"\"\n",
    "    Parse GPT_response string of the form 'angle1, angle2, decision'\n",
    "    → (float, float, str). Returns NaN if parsing fails.\n",
    "    \"\"\"\n",
    "    if not isinstance(resp, str):\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    parts = [p.strip() for p in resp.split(\",\")]\n",
    "    if len(parts) < 3:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    try:\n",
    "        a1 = float(parts[0])\n",
    "        a2 = float(parts[1])\n",
    "        decision = parts[2].lower()\n",
    "        return (a1, a2, decision)\n",
    "    except Exception:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "# --- Parse function to add columns\n",
    "def add_parsed_columns(df):\n",
    "    df = df.copy()\n",
    "    parsed = df[\"GPT_response\"].apply(parse_gpt_response)\n",
    "    df[[\"est_angle_1\", \"est_angle_2\", \"decision\"]] = pd.DataFrame(parsed.tolist(), index=df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "gemini_50_50 = add_parsed_columns(datasets.get(\"50_50\", pd.DataFrame()))\n",
    "gemini_80_20 = add_parsed_columns(datasets.get(\"80_20\", pd.DataFrame()))\n",
    "gemini_100_0 = add_parsed_columns(datasets.get(\"100_0\", pd.DataFrame()))\n",
    "\n",
    "\n",
    "datasets[\"50_50_parsed\"] = gemini_50_50\n",
    "datasets[\"80_20_parsed\"] = gemini_80_20\n",
    "datasets[\"100_0_parsed\"] = gemini_100_0\n",
    "\n",
    "display(gemini_100_0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "043a5ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>n_trials</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>false_alarm_rate</th>\n",
       "      <th>TP_hits</th>\n",
       "      <th>FP_false_alarms</th>\n",
       "      <th>TN_correct_rejects</th>\n",
       "      <th>FN_misses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.228</td>\n",
       "      <td>485</td>\n",
       "      <td>114</td>\n",
       "      <td>386</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50_50</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.186</td>\n",
       "      <td>458</td>\n",
       "      <td>93</td>\n",
       "      <td>407</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80_20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.254</td>\n",
       "      <td>472</td>\n",
       "      <td>127</td>\n",
       "      <td>373</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  n_trials  accuracy  hit_rate  false_alarm_rate  TP_hits  \\\n",
       "0     100_0      1000     0.871     0.970             0.228      485   \n",
       "1     50_50      1000     0.865     0.916             0.186      458   \n",
       "2     80_20      1000     0.845     0.944             0.254      472   \n",
       "\n",
       "   FP_false_alarms  TN_correct_rejects  FN_misses  \n",
       "0              114                 386         15  \n",
       "1               93                 407         42  \n",
       "2              127                 373         28  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Accuracy / SDT metrics for the three parsed Gemini datasets ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper: ensure the three parsed DataFrames exist and are tagged with condition\n",
    "def ensure_condition(df: pd.DataFrame, cond: str) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    if \"condition\" not in d.columns:\n",
    "        d[\"condition\"] = cond\n",
    "    else:\n",
    "        d[\"condition\"] = (\n",
    "            d[\"condition\"].astype(str)\n",
    "            .str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "            .str.replace(\"-\", \"_\").str.replace(\"__\", \"_\")\n",
    "        )\n",
    "        # backfill with provided cond if missing/blank\n",
    "        d.loc[d[\"condition\"].isna() | (d[\"condition\"] == \"\"), \"condition\"] = cond\n",
    "    return d\n",
    "\n",
    "# --- Helper: if parsed cols missing, parse GPT_response\n",
    "def parse_gpt_response(resp):\n",
    "    if not isinstance(resp, str):\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    parts = [p.strip() for p in resp.split(\",\")]\n",
    "    if len(parts) < 3:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "    try:\n",
    "        a1 = float(parts[0]); a2 = float(parts[1]); decision = parts[2].strip().lower()\n",
    "        return (a1, a2, decision)\n",
    "    except Exception:\n",
    "        return (np.nan, np.nan, np.nan)\n",
    "\n",
    "def ensure_parsed_columns(d: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = d.copy()\n",
    "    need_parse = not {\"est_angle_1\", \"est_angle_2\", \"decision\"}.issubset(d.columns)\n",
    "    if need_parse and \"GPT_response\" in d.columns:\n",
    "        parsed = d[\"GPT_response\"].apply(parse_gpt_response).tolist()\n",
    "        d[[\"est_angle_1\", \"est_angle_2\", \"decision\"]] = pd.DataFrame(parsed, index=d.index)\n",
    "    return d\n",
    "\n",
    "# --- Bring together the three parsed datasets\n",
    "parts = []\n",
    "for cond, df_part in [(\"50_50\", gemini_50_50), (\"80_20\", gemini_80_20), (\"100_0\", gemini_100_0)]:\n",
    "    if isinstance(df_part, pd.DataFrame) and not df_part.empty:\n",
    "        d = ensure_condition(df_part, cond)\n",
    "        d = ensure_parsed_columns(d)\n",
    "        parts.append(d)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing or empty dataset for {cond}\")\n",
    "\n",
    "if not parts:\n",
    "    raise ValueError(\"No parsed Gemini datasets available. Make sure gemini_50_50/80_20/100_0 exist.\")\n",
    "\n",
    "df_all = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "# --- Compute metrics by condition\n",
    "def metrics_by_condition(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "\n",
    "    # map decision -> prediction\n",
    "    d[\"pred\"] = d[\"decision\"].map({\"present\": 1, \"absent\": 0})\n",
    "    d = d.dropna(subset=[\"pred\", \"TP\", \"condition\"]).copy()\n",
    "\n",
    "    # normalize & order condition labels\n",
    "    order = [\"50_50\", \"80_20\", \"100_0\"]\n",
    "    d[\"condition\"] = (\n",
    "        d[\"condition\"].astype(str)\n",
    "        .str.strip().str.replace(r\"\\s+\", \"\", regex=True)\n",
    "        .str.replace(\"-\", \"_\").str.replace(\"__\", \"_\")\n",
    "    )\n",
    "    d[\"condition\"] = pd.Categorical(d[\"condition\"], categories=order, ordered=True)\n",
    "\n",
    "    rows = []\n",
    "    for cond, sub in d.groupby(\"condition\", observed=True):\n",
    "        if pd.isna(cond):\n",
    "            continue\n",
    "        total = len(sub)\n",
    "        tp = ((sub[\"pred\"] == 1) & (sub[\"TP\"] == 1)).sum()\n",
    "        fp = ((sub[\"pred\"] == 1) & (sub[\"TP\"] == 0)).sum()\n",
    "        tn = ((sub[\"pred\"] == 0) & (sub[\"TP\"] == 0)).sum()\n",
    "        fn = ((sub[\"pred\"] == 0) & (sub[\"TP\"] == 1)).sum()\n",
    "\n",
    "        accuracy = (tp + tn) / total if total else np.nan\n",
    "        hit_rate = tp / (tp + fn) if (tp + fn) else np.nan\n",
    "        fa_rate = fp / (fp + tn) if (fp + tn) else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"condition\": cond,\n",
    "            \"n_trials\": int(total),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"hit_rate\": hit_rate,\n",
    "            \"false_alarm_rate\": fa_rate,\n",
    "            \"TP_hits\": int(tp),\n",
    "            \"FP_false_alarms\": int(fp),\n",
    "            \"TN_correct_rejects\": int(tn),\n",
    "            \"FN_misses\": int(fn),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"condition\").reset_index(drop=True)\n",
    "\n",
    "# --- Run & display\n",
    "\n",
    "gemini_metrics = metrics_by_condition(df_all)\n",
    "display(gemini_metrics)\n",
    "\n",
    "# Also break out per-dataset (if you want individual variables)\n",
    "metrics_50_50 = gemini_metrics.loc[gemini_metrics[\"condition\"] == \"50_50\"].reset_index(drop=True)\n",
    "metrics_80_20 = gemini_metrics.loc[gemini_metrics[\"condition\"] == \"80_20\"].reset_index(drop=True)\n",
    "metrics_100_0 = gemini_metrics.loc[gemini_metrics[\"condition\"] == \"100_0\"].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "871a7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_mag_line1</th>\n",
       "      <th>MAE_mag_line2</th>\n",
       "      <th>RMSE_mag_line1</th>\n",
       "      <th>RMSE_mag_line2</th>\n",
       "      <th>Bias_mag_line1</th>\n",
       "      <th>Bias_mag_line2</th>\n",
       "      <th>Corr_mag_line1</th>\n",
       "      <th>Corr_mag_line2</th>\n",
       "      <th>n_trials</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50_50</th>\n",
       "      <td>1.617646</td>\n",
       "      <td>1.663294</td>\n",
       "      <td>2.176531</td>\n",
       "      <td>2.175877</td>\n",
       "      <td>-1.221681</td>\n",
       "      <td>-0.49598</td>\n",
       "      <td>0.940647</td>\n",
       "      <td>0.933267</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80_20</th>\n",
       "      <td>1.451960</td>\n",
       "      <td>1.766039</td>\n",
       "      <td>1.970698</td>\n",
       "      <td>2.309326</td>\n",
       "      <td>-0.749881</td>\n",
       "      <td>-0.41375</td>\n",
       "      <td>0.942629</td>\n",
       "      <td>0.927198</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100_0</th>\n",
       "      <td>1.689481</td>\n",
       "      <td>1.787509</td>\n",
       "      <td>2.345441</td>\n",
       "      <td>2.374318</td>\n",
       "      <td>-0.418281</td>\n",
       "      <td>-0.32408</td>\n",
       "      <td>0.911256</td>\n",
       "      <td>0.914494</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAE_mag_line1  MAE_mag_line2  RMSE_mag_line1  RMSE_mag_line2  \\\n",
       "50_50       1.617646       1.663294        2.176531        2.175877   \n",
       "80_20       1.451960       1.766039        1.970698        2.309326   \n",
       "100_0       1.689481       1.787509        2.345441        2.374318   \n",
       "\n",
       "       Bias_mag_line1  Bias_mag_line2  Corr_mag_line1  Corr_mag_line2  \\\n",
       "50_50       -1.221681        -0.49598        0.940647        0.933267   \n",
       "80_20       -0.749881        -0.41375        0.942629        0.927198   \n",
       "100_0       -0.418281        -0.32408        0.911256        0.914494   \n",
       "\n",
       "       n_trials  \n",
       "50_50    1000.0  \n",
       "80_20    1000.0  \n",
       "100_0    1000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Angle-estimation metrics using MAGNITUDES ONLY ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_angle_metrics_magnitude(df: pd.DataFrame) -> pd.Series:\n",
    "    d = df.copy()\n",
    "\n",
    "    # Ensure needed columns exist\n",
    "    needed = {\"est_angle_1\", \"est_angle_2\", \"line1_angle\", \"line2_angle\"}\n",
    "    missing = needed - set(d.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns for magnitude metrics: {missing}\")\n",
    "\n",
    "    # Drop rows with NaNs in required fields\n",
    "    d = d.dropna(subset=list(needed)).copy()\n",
    "\n",
    "    # Compare absolute magnitudes (ignore sign)\n",
    "    d[\"true1_mag\"] = d[\"line1_angle\"].abs()\n",
    "    d[\"true2_mag\"] = d[\"line2_angle\"].abs()\n",
    "    d[\"est1_mag\"]  = d[\"est_angle_1\"].abs()\n",
    "    d[\"est2_mag\"]  = d[\"est_angle_2\"].abs()\n",
    "\n",
    "    # Signed error in magnitude space (can be useful for bias)\n",
    "    d[\"err1_mag\"] = d[\"est1_mag\"] - d[\"true1_mag\"]\n",
    "    d[\"err2_mag\"] = d[\"est2_mag\"] - d[\"true2_mag\"]\n",
    "\n",
    "    # Absolute error in magnitude space\n",
    "    d[\"abs_err1_mag\"] = d[\"err1_mag\"].abs()\n",
    "    d[\"abs_err2_mag\"] = d[\"err2_mag\"].abs()\n",
    "\n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"MAE_mag_line1\": d[\"abs_err1_mag\"].mean(),\n",
    "        \"MAE_mag_line2\": d[\"abs_err2_mag\"].mean(),\n",
    "        \"RMSE_mag_line1\": np.sqrt((d[\"err1_mag\"]**2).mean()),\n",
    "        \"RMSE_mag_line2\": np.sqrt((d[\"err2_mag\"]**2).mean()),\n",
    "        \"Bias_mag_line1\": d[\"err1_mag\"].mean(),  # + means overestimating magnitude\n",
    "        \"Bias_mag_line2\": d[\"err2_mag\"].mean(),\n",
    "        \"Corr_mag_line1\": d[[\"est1_mag\", \"true1_mag\"]].corr().iloc[0,1],\n",
    "        \"Corr_mag_line2\": d[[\"est2_mag\", \"true2_mag\"]].corr().iloc[0,1],\n",
    "        \"n_trials\": len(d),\n",
    "    }\n",
    "    return pd.Series(metrics)\n",
    "\n",
    "# Compute per-condition (expects parsed DataFrames already exist)\n",
    "angle_metrics_mag = pd.DataFrame({\n",
    "    \"50_50\": compute_angle_metrics_magnitude(gemini_50_50),\n",
    "    \"80_20\": compute_angle_metrics_magnitude(gemini_80_20),\n",
    "    \"100_0\": compute_angle_metrics_magnitude(gemini_100_0),\n",
    "}).T\n",
    "\n",
    "display(angle_metrics_mag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexwisdom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
