{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a7067b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/AdamR/OneDrive/UCSB/VIU/HonorsThesis/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd() / \"notebooks\"))  # so we can import _utils from notebooks/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from _utils import get_data_dir\n",
    "\n",
    "DATA_DIR = get_data_dir()\n",
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dec0186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded datasets: ['50_50', '80_20', '100_0']\n"
     ]
    }
   ],
   "source": [
    "# === Load human + model CSVs for 50_50, 80_20, and 100_0 datasets ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = DATA_DIR  # already defined in your environment\n",
    "FOLDERS = [\"50_50\", \"80_20\", \"100_0\"]\n",
    "\n",
    "def safe_read_csv(path: Path, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Robust CSV reader with fallback parsing.\"\"\"\n",
    "    defaults = dict(low_memory=False, encoding_errors=\"ignore\")\n",
    "    defaults.update(kwargs)\n",
    "    try:\n",
    "        return pd.read_csv(path, **defaults)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, engine=\"python\", sep=None, **defaults)\n",
    "\n",
    "def load_dataset(folder: Path) -> dict:\n",
    "    \"\"\"Load human_data.csv and all model decision CSVs inside 'decisions/'.\"\"\"\n",
    "    human_path = folder / \"human_data.csv\"\n",
    "    decisions_dir = folder / \"decisions\"\n",
    "\n",
    "    if not human_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing human_data.csv in {folder}\")\n",
    "    if not decisions_dir.exists():\n",
    "        raise FileNotFoundError(f\"Missing 'decisions/' subfolder in {folder}\")\n",
    "\n",
    "    # Load human data\n",
    "    human_df = safe_read_csv(human_path)\n",
    "\n",
    "    # Load each model file\n",
    "    models = {}\n",
    "    for csv_path in sorted(decisions_dir.glob(\"*.csv\")):\n",
    "        model_name = csv_path.stem\n",
    "        models[model_name] = safe_read_csv(csv_path)\n",
    "\n",
    "    return {\n",
    "        \"human\": human_df,\n",
    "        \"human_path\": human_path,\n",
    "        \"models\": models,\n",
    "        \"model_paths\": {m: csv_path for m, csv_path in zip(models.keys(), sorted(decisions_dir.glob('*.csv')))}\n",
    "    }\n",
    "\n",
    "# === Main loading loop ===\n",
    "datasets: dict[str, dict] = {}\n",
    "records = []\n",
    "\n",
    "for name in FOLDERS:\n",
    "    folder = ROOT / name\n",
    "    if not folder.exists():\n",
    "        print(f\"⚠️ Warning: Folder '{name}' not found under {ROOT}\")\n",
    "        continue\n",
    "\n",
    "    data_bundle = load_dataset(folder)\n",
    "    datasets[name] = data_bundle\n",
    "\n",
    "    # Record human file\n",
    "    h = data_bundle[\"human\"]\n",
    "    records.append({\n",
    "        \"dataset\": name,\n",
    "        \"kind\": \"human\",\n",
    "        \"name\": \"human_data\",\n",
    "        \"n_rows\": len(h),\n",
    "        \"n_cols\": h.shape[1],\n",
    "        \"path\": str(data_bundle[\"human_path\"].resolve())\n",
    "    })\n",
    "\n",
    "    # Record model files\n",
    "    for mname, mdf in data_bundle[\"models\"].items():\n",
    "        records.append({\n",
    "            \"dataset\": name,\n",
    "            \"kind\": \"model\",\n",
    "            \"name\": mname,\n",
    "            \"n_rows\": len(mdf),\n",
    "            \"n_cols\": mdf.shape[1],\n",
    "            \"path\": str((folder / \"decisions\" / f\"{mname}.csv\").resolve())\n",
    "        })\n",
    "\n",
    "# === Summary table ===\n",
    "assignment_index = pd.DataFrame.from_records(records).sort_values(\n",
    "    [\"dataset\", \"kind\", \"name\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Loaded datasets: {list(datasets.keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d754e9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>side_selected</th>\n",
       "      <th>cue_points</th>\n",
       "      <th>line1_angle</th>\n",
       "      <th>line2_angle</th>\n",
       "      <th>valid_cue</th>\n",
       "      <th>TP</th>\n",
       "      <th>GPT_response</th>\n",
       "      <th>condition</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>1.921956</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>present</td>\n",
       "      <td>50_50</td>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>absent</td>\n",
       "      <td>50_50</td>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.314827</td>\n",
       "      <td>6.508956</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>absent</td>\n",
       "      <td>50_50</td>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.775056</td>\n",
       "      <td>15.054317</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>present</td>\n",
       "      <td>50_50</td>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.222230</td>\n",
       "      <td>19.885165</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>absent</td>\n",
       "      <td>50_50</td>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id  side_selected  cue_points  line1_angle  line2_angle  valid_cue  \\\n",
       "0       100              1           2    14.314827     1.921956      False   \n",
       "1       845              1           2    15.054317     4.222230      False   \n",
       "2       245              1           1    14.314827     6.508956       True   \n",
       "3        72              2           2     8.775056    15.054317       True   \n",
       "4       469              2           2     4.222230    19.885165       True   \n",
       "\n",
       "     TP GPT_response condition                            model_name  \n",
       "0  True      present     50_50  0responses_claude-3-5-haiku-20241022  \n",
       "1  True       absent     50_50  0responses_claude-3-5-haiku-20241022  \n",
       "2  True       absent     50_50  0responses_claude-3-5-haiku-20241022  \n",
       "3  True      present     50_50  0responses_claude-3-5-haiku-20241022  \n",
       "4  True       absent     50_50  0responses_claude-3-5-haiku-20241022  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "root = DATA_DIR  # contains folders 50_50, 80_20, 100_0\n",
    "conditions = [\"50_50\", \"80_20\", \"100_0\"]\n",
    "all_conditions = {}\n",
    "\n",
    "for cond in conditions:\n",
    "    files = glob.glob(str(root / cond / \"decisions\" / \"*.csv\"))\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        model_name = Path(f).stem\n",
    "        df = pd.read_csv(f)\n",
    "        df[\"condition\"] = cond\n",
    "        df[\"model_name\"] = model_name\n",
    "        dfs.append(df)\n",
    "    all_conditions[cond] = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional single master DataFrame:\n",
    "models_df = pd.concat(all_conditions.values(), ignore_index=True)\n",
    "\n",
    "models_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc3a8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== UNIQUE VALUE SUMMARY: n_rows = 36,000 ===\n",
      "\n",
      "\n",
      "▶ Column: 'image_id'\n",
      "   • Unique count: 1000\n",
      "   • First 12 unique values: [100, 845, 245, 72, 469, 468, 923, 646, 672, 275, 712, 448] ...\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_id\n",
       "100    36\n",
       "680    36\n",
       "679    36\n",
       "973    36\n",
       "520    36\n",
       "531    36\n",
       "744    36\n",
       "630    36\n",
       "93     36\n",
       "840    36\n",
       "123    36\n",
       "484    36\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'side_selected'\n",
      "   • Unique count: 2\n",
      "   • Unique values: [1, 2]\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "side_selected\n",
       "1    18504\n",
       "2    17496\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'cue_points'\n",
      "   • Unique count: 2\n",
      "   • Unique values: [2, 1]\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cue_points\n",
       "1    18492\n",
       "2    17508\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'line1_angle'\n",
      "   • Unique count: 40\n",
      "   • First 12 unique values: [14.31482691040488, 15.05431655960486, 8.775055744479694, 4.222230206142679, 6.5089564405024944, 13.392497753751124, 10.40771131249005, 19.885165113855454, 2.6897703231505687, 16.735995851476087, 7.266954405811635, 4.986333771235535] ...\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "line1_angle\n",
       "4.222230     2520\n",
       "4.986334     2340\n",
       "3.456619     2196\n",
       "7.266954     2124\n",
       "5.748663     2088\n",
       "6.508956     2052\n",
       "8.022404     1692\n",
       "2.689770     1476\n",
       "1.921956     1404\n",
       "8.775056     1296\n",
       "11.908300    1296\n",
       "9.651833     1188\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'line2_angle'\n",
      "   • Unique count: 42\n",
      "   • First 12 unique values: [1.921955958931289, 4.222230206142679, 6.5089564405024944, 15.05431655960486, 19.885165113855454, 17.468023251277728, 8.775055744479694, -1.1534504511055996, 16.735995851476087, 2.6897703231505687, -3.4566191720419983, 14.31482691040488] ...\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "line2_angle\n",
       "4.986334     2736\n",
       "5.748663     2592\n",
       "6.508956     2160\n",
       "4.222230     2160\n",
       "7.266954     2160\n",
       "3.456619     2088\n",
       "1.921956     1872\n",
       "2.689770     1836\n",
       "8.022404     1656\n",
       "8.775056     1404\n",
       "1.153450     1224\n",
       "11.159944    1044\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'valid_cue'\n",
      "   • Unique count: 2\n",
      "   • Unique values: [False, True]\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "valid_cue\n",
       "True     23076\n",
       "False    12924\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'TP'\n",
      "   • Unique count: 2\n",
      "   • Unique values: [True, False]\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TP\n",
       "True     18000\n",
       "False    18000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'GPT_response'\n",
      "   • Unique count: 2\n",
      "   • Unique values: ['present', 'absent']\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT_response\n",
       "present    19149\n",
       "absent     16851\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'condition'\n",
      "   • Unique count: 3\n",
      "   • Unique values: ['50_50', '80_20', '100_0']\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "condition\n",
       "50_50    12000\n",
       "80_20    12000\n",
       "100_0    12000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Column: 'model_name'\n",
      "   • Unique count: 12\n",
      "   • Unique values: ['0responses_claude-3-5-haiku-20241022', '0responses_claude-3-7-sonnet-20250219', '0responses_claude-opus-4-20250514', '0responses_claude-sonnet-4-20250514', '0responses_gemini-2.5-flash-lite-preview-06-17', '0responses_gemini-2.5-flash', '0responses_gemini-2.5-pro', '0responses_gpt-4.1-2025-04-14', '0responses_gpt-5-2025-08-07', '0responses_gpt-5-mini-2025-08-07', '0responses_o3-2025-04-16', '0responses_o4-mini-2025-04-16']\n",
      "   • Value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "0responses_claude-3-5-haiku-20241022              3000\n",
       "0responses_claude-3-7-sonnet-20250219             3000\n",
       "0responses_claude-opus-4-20250514                 3000\n",
       "0responses_claude-sonnet-4-20250514               3000\n",
       "0responses_gemini-2.5-flash-lite-preview-06-17    3000\n",
       "0responses_gemini-2.5-flash                       3000\n",
       "0responses_gemini-2.5-pro                         3000\n",
       "0responses_gpt-4.1-2025-04-14                     3000\n",
       "0responses_gpt-5-2025-08-07                       3000\n",
       "0responses_gpt-5-mini-2025-08-07                  3000\n",
       "0responses_o3-2025-04-16                          3000\n",
       "0responses_o4-mini-2025-04-16                     3000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary: Unique Value Counts per Column\n",
    "\n",
    "def summarize_uniques(df: pd.DataFrame, max_display: int = 12):\n",
    "    \"\"\"\n",
    "    For each column, prints:\n",
    "    - Number of unique values\n",
    "    - Example of up to 12 unique values\n",
    "    - Value counts for up to 12 most frequent values\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== UNIQUE VALUE SUMMARY: n_rows = {len(df):,} ===\\n\")\n",
    "    for col in df.columns:\n",
    "        n_unique = df[col].nunique(dropna=True)\n",
    "        uniques = df[col].dropna().unique()[:max_display]\n",
    "        print(f\"\\n▶ Column: '{col}'\")\n",
    "        print(f\"   • Unique count: {n_unique}\")\n",
    "        if n_unique <= max_display:\n",
    "            print(f\"   • Unique values: {uniques.tolist()}\")\n",
    "        else:\n",
    "            print(f\"   • First {max_display} unique values: {uniques.tolist()} ...\")\n",
    "        # Value counts (top 12)\n",
    "        print(\"   • Value counts:\")\n",
    "        display(df[col].value_counts(dropna=False).head(max_display))\n",
    "\n",
    "# Example usage\n",
    "summarize_uniques(models_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63349bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model Hit / False Alarm Rates ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamR\\AppData\\Local\\Temp\\ipykernel_23492\\3979222492.py:19: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>hit_mean</th>\n",
       "      <th>hit_sem</th>\n",
       "      <th>fa_mean</th>\n",
       "      <th>fa_sem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50_50</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80_20</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  hit_mean  hit_sem  fa_mean  fa_sem\n",
       "0     100_0     0.501    0.040    0.536   0.035\n",
       "1     50_50     0.513    0.045    0.544   0.044\n",
       "2     80_20     0.536    0.051    0.561   0.048"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute model hit and false alarm rates\n",
    "\n",
    "def compute_model_hit_fa(MODELS_DF: pd.DataFrame):\n",
    "    df = MODELS_DF.copy()\n",
    "    df[\"GPT_response\"] = (\n",
    "        df[\"GPT_response\"].astype(str).str.strip().str.lower()\n",
    "        .replace({\"true\": \"present\", \"false\": \"absent\"})\n",
    "    )\n",
    "    df[\"present_choice\"] = df[\"GPT_response\"].map({\"present\": 1, \"absent\": 0})\n",
    "    df[\"TP\"] = pd.to_numeric(df[\"TP\"], errors=\"coerce\").astype(int)\n",
    "\n",
    "    results = (\n",
    "        df.groupby([\"condition\", \"model_name\"])\n",
    "          .apply(lambda g: pd.Series({\n",
    "              \"hit_rate\": np.mean(g.loc[g[\"TP\"] == 1, \"present_choice\"])\n",
    "                          if (g[\"TP\"] == 1).any() else np.nan,\n",
    "              \"fa_rate\":  np.mean(g.loc[g[\"TP\"] == 0, \"present_choice\"])\n",
    "                          if (g[\"TP\"] == 0).any() else np.nan\n",
    "          }))\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    # Mean ± SEM across models per condition\n",
    "    summary = (\n",
    "        results.groupby(\"condition\", as_index=False)\n",
    "               .agg(hit_mean=(\"hit_rate\", \"mean\"),\n",
    "                    hit_sem=(\"hit_rate\", lambda x: x.std(ddof=1)/np.sqrt(x.count())),\n",
    "                    fa_mean=(\"fa_rate\", \"mean\"),\n",
    "                    fa_sem=(\"fa_rate\", lambda x: x.std(ddof=1)/np.sqrt(x.count())))\n",
    "    )\n",
    "\n",
    "    print(\"=== Model Hit / False Alarm Rates ===\")\n",
    "    display(summary.round(3))\n",
    "    return results, summary\n",
    "\n",
    "\n",
    "model_rates, model_summary = compute_model_hit_fa(models_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cfd687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50_50: model-ensemble majority accuracy = 0.4860 | trials=1000 | models=12\n",
      "80_20: model-ensemble majority accuracy = 0.4770 | trials=1000 | models=12\n",
      "100_0: model-ensemble majority accuracy = 0.4770 | trials=1000 | models=12\n",
      "\n",
      "Combined model-ensemble accuracy across all conditions: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50_50</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80_20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  trials  accuracy\n",
       "0     100_0    1000     0.477\n",
       "1     50_50    1000     0.486\n",
       "2     80_20    1000     0.477"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Majority-vote accuracy for MODEL ENSEMBLES (schema: image_id, TP, GPT_response) ===\n",
    "# Uses the 'datasets' dict you created earlier.\n",
    "# Each CSV in datasets[COND][\"models\"] is one \"participant\" in the ensemble.\n",
    "\n",
    "def compute_model_majority_vote(\n",
    "    model_dfs: dict[str, pd.DataFrame],\n",
    "    condition_label: str,\n",
    "    trial_col: str = \"image_id\",\n",
    "    truth_col: str = \"TP\",\n",
    "    response_col: str = \"GPT_response\",\n",
    "    tie_rule: str = \">\"   # use \">=\" to break ties toward \"present\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a per-trial table by majority-voting across models.\n",
    "    Returns columns: [image_id, pred, truth, condition, n_models, correct]\n",
    "    \"\"\"\n",
    "    if not model_dfs:\n",
    "        raise ValueError(f\"No model CSVs found for condition {condition_label}.\")\n",
    "\n",
    "    # 1) Stack all model decisions\n",
    "    recs = []\n",
    "    mapping = {\"present\": 1, \"absent\": 0, \"1\": 1, \"0\": 0, \"yes\": 1, \"no\": 0}\n",
    "    for model_name, df in model_dfs.items():\n",
    "        for col in (trial_col, truth_col, response_col):\n",
    "            if col not in df.columns:\n",
    "                raise KeyError(f\"[{condition_label} / {model_name}] missing column: '{col}'\")\n",
    "\n",
    "        tmp = df[[trial_col, truth_col, response_col]].copy()\n",
    "        # Normalize responses to binary\n",
    "        tmp[response_col] = tmp[response_col].astype(str).str.strip().str.lower()\n",
    "        tmp[\"model_decision\"] = tmp[response_col].map(mapping)\n",
    "\n",
    "        if tmp[\"model_decision\"].isna().any():\n",
    "            bad_vals = sorted(tmp.loc[tmp[\"model_decision\"].isna(), response_col].unique().tolist())\n",
    "            raise ValueError(f\"[{condition_label} / {model_name}] Unmapped GPT_response values: {bad_vals}\")\n",
    "\n",
    "        tmp[\"model_name\"] = model_name\n",
    "        recs.append(tmp[[trial_col, truth_col, \"model_name\", \"model_decision\"]])\n",
    "\n",
    "    stacked = pd.concat(recs, ignore_index=True)\n",
    "\n",
    "    # 2) Majority vote across models per trial\n",
    "    prop_present = stacked.groupby(trial_col)[\"model_decision\"].mean()\n",
    "    if tie_rule not in {\">\", \">=\"}:\n",
    "        raise ValueError(\"tie_rule must be '>' or '>='.\")\n",
    "    trial_pred = ((prop_present >= 0.5) if tie_rule == \">=\" else (prop_present > 0.5)).astype(int).rename(\"pred\")\n",
    "\n",
    "    # 3) Truth per trial (mode fallback, warn if inconsistent)\n",
    "    tp_grp = stacked.groupby(trial_col)[truth_col]\n",
    "    trial_truth = tp_grp.agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean()))).astype(int)\n",
    "\n",
    "    n_inconsistent = int((tp_grp.nunique() > 1).sum())\n",
    "    if n_inconsistent > 0:\n",
    "        print(f\"⚠️ {condition_label}: {n_inconsistent} trial(s) had inconsistent TP across files; using per-trial mode.\")\n",
    "\n",
    "    # 4) Assemble trial table and compute accuracy\n",
    "    tt = pd.concat([trial_pred, trial_truth.rename(\"truth\")], axis=1).reset_index()\n",
    "    tt[\"condition\"] = condition_label\n",
    "    tt[\"n_models\"] = len(model_dfs)\n",
    "    tt[\"correct\"] = (tt[\"pred\"] == tt[\"truth\"]).astype(int)\n",
    "\n",
    "    acc = tt[\"correct\"].mean()\n",
    "    print(f\"{condition_label}: model-ensemble majority accuracy = {acc:.4f} | trials={len(tt)} | models={len(model_dfs)}\")\n",
    "    return tt\n",
    "\n",
    "\n",
    "# === Run for each dataset folder you loaded earlier ===\n",
    "model_results = []\n",
    "for cond_label, bundle in datasets.items():  # e.g., \"50_50\", \"80_20\", \"100_0\"\n",
    "    tt = compute_model_majority_vote(\n",
    "        model_dfs=bundle[\"models\"],\n",
    "        condition_label=cond_label,\n",
    "        trial_col=\"image_id\",\n",
    "        truth_col=\"TP\",\n",
    "        response_col=\"GPT_response\",\n",
    "        tie_rule=\">\"     # change to \">=\" to tie-break toward \"present\"\n",
    "    )\n",
    "    model_results.append(tt)\n",
    "\n",
    "combined_models = pd.concat(model_results, ignore_index=True)\n",
    "\n",
    "# Summary\n",
    "overall_acc = combined_models[\"correct\"].mean()\n",
    "by_condition = (\n",
    "    combined_models.groupby(\"condition\", as_index=False)\n",
    "    .agg(trials=(\"image_id\", \"nunique\"), accuracy=(\"correct\", \"mean\"))\n",
    "    .sort_values(\"condition\")\n",
    ")\n",
    "\n",
    "print(f\"\\nCombined model-ensemble accuracy across all conditions: {overall_acc:.4f}\")\n",
    "display(by_condition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9be7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_fit</th>\n",
       "      <th>trials</th>\n",
       "      <th>n_models</th>\n",
       "      <th>rank_Sigma</th>\n",
       "      <th>lambda</th>\n",
       "      <th>best_threshold</th>\n",
       "      <th>overall_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALL</td>\n",
       "      <td>3000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.030921</td>\n",
       "      <td>0.536667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition_fit  trials  n_models  rank_Sigma    lambda  best_threshold  \\\n",
       "0           ALL    3000        12          12  0.000001       -0.030921   \n",
       "\n",
       "   overall_accuracy  \n",
       "0          0.536667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>trials</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>D_mean</th>\n",
       "      <th>D_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>0.180225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50_50</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.538</td>\n",
       "      <td>-0.019212</td>\n",
       "      <td>0.156988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80_20</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.531</td>\n",
       "      <td>-0.006725</td>\n",
       "      <td>0.172722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition  trials  accuracy    D_mean     D_std\n",
       "0     100_0    1000     0.541  0.025937  0.180225\n",
       "1     50_50    1000     0.538 -0.019212  0.156988\n",
       "2     80_20    1000     0.531 -0.006725  0.172722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>weight</th>\n",
       "      <th>Delta_mu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0responses_claude-3-7-sonnet-20250219</td>\n",
       "      <td>0.190728</td>\n",
       "      <td>-0.019333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0responses_claude-sonnet-4-20250514</td>\n",
       "      <td>0.137368</td>\n",
       "      <td>-0.018667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0responses_gemini-2.5-flash-lite-preview-06-17</td>\n",
       "      <td>0.121923</td>\n",
       "      <td>-0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0responses_gemini-2.5-pro</td>\n",
       "      <td>0.089671</td>\n",
       "      <td>-0.020667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0responses_gpt-5-2025-08-07</td>\n",
       "      <td>-0.033049</td>\n",
       "      <td>-0.031333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0responses_gemini-2.5-flash</td>\n",
       "      <td>-0.036858</td>\n",
       "      <td>-0.035333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0responses_gpt-5-mini-2025-08-07</td>\n",
       "      <td>-0.056686</td>\n",
       "      <td>-0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0responses_o4-mini-2025-04-16</td>\n",
       "      <td>-0.065138</td>\n",
       "      <td>-0.027333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0responses_o3-2025-04-16</td>\n",
       "      <td>-0.124537</td>\n",
       "      <td>-0.036667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0responses_claude-3-5-haiku-20241022</td>\n",
       "      <td>-0.131421</td>\n",
       "      <td>-0.042667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0responses_claude-opus-4-20250514</td>\n",
       "      <td>-0.185978</td>\n",
       "      <td>-0.047333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0responses_gpt-4.1-2025-04-14</td>\n",
       "      <td>-0.228377</td>\n",
       "      <td>-0.058000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model_name    weight  Delta_mu\n",
       "0            0responses_claude-3-7-sonnet-20250219  0.190728 -0.019333\n",
       "1              0responses_claude-sonnet-4-20250514  0.137368 -0.018667\n",
       "2   0responses_gemini-2.5-flash-lite-preview-06-17  0.121923 -0.004667\n",
       "3                        0responses_gemini-2.5-pro  0.089671 -0.020667\n",
       "4                      0responses_gpt-5-2025-08-07 -0.033049 -0.031333\n",
       "5                      0responses_gemini-2.5-flash -0.036858 -0.035333\n",
       "6                 0responses_gpt-5-mini-2025-08-07 -0.056686 -0.029333\n",
       "7                    0responses_o4-mini-2025-04-16 -0.065138 -0.027333\n",
       "8                         0responses_o3-2025-04-16 -0.124537 -0.036667\n",
       "9             0responses_claude-3-5-haiku-20241022 -0.131421 -0.042667\n",
       "10               0responses_claude-opus-4-20250514 -0.185978 -0.047333\n",
       "11                   0responses_gpt-4.1-2025-04-14 -0.228377 -0.058000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# WLC for MODELS (binary)\n",
    "# =========================\n",
    "def wlc_models(\n",
    "    MODELS_DF: pd.DataFrame,\n",
    "    center_by_model: bool = True,\n",
    "    standardize: bool = False,\n",
    "    reg_lambda: float = 1e-6,\n",
    "    tie_rule: str = \">\",          # '>' => equal-threshold -> absent ; '>=' => equal -> present\n",
    "    fit_per_condition: bool = False  # if True: fit separate WLC per condition\n",
    "):\n",
    "    # ---------- Sanity checks ----------\n",
    "    req = {\"image_id\",\"condition\",\"model_name\",\"GPT_response\",\"TP\"}\n",
    "    missing = req - set(MODELS_DF.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    df = MODELS_DF.copy()\n",
    "\n",
    "    # Normalize GPT_response -> binary (1=present, 0=absent)\n",
    "    df[\"GPT_response\"] = (\n",
    "        df[\"GPT_response\"].astype(str).str.strip().str.lower()\n",
    "        .replace({\"true\":\"present\",\"false\":\"absent\"})\n",
    "    )\n",
    "    df[\"pred_bin\"] = df[\"GPT_response\"].map({\"present\":1, \"absent\":0}).astype(\"float\")\n",
    "\n",
    "    # Coerce TP\n",
    "    df[\"TP\"] = pd.to_numeric(df[\"TP\"], errors=\"coerce\").astype(int)\n",
    "\n",
    "    # ---------- Enforce uniqueness at (image_id, condition, model_name) ----------\n",
    "    # If a model has multiple rows on the same trial, average its binary predictions (still in [0,1]).\n",
    "    df_uni = (\n",
    "        df.groupby([\"image_id\",\"condition\",\"model_name\"], as_index=False)\n",
    "          .agg(pred_bin=(\"pred_bin\",\"mean\"))\n",
    "    )\n",
    "\n",
    "    # Truth per (image_id, condition)\n",
    "    truth_ic = (\n",
    "        df.groupby([\"image_id\",\"condition\"])[\"TP\"]\n",
    "          .agg(lambda s: s.mode().iloc[0] if not s.mode().empty else int(round(s.mean())))\n",
    "          .astype(int)\n",
    "    )\n",
    "\n",
    "    # Helper: fit WLC on a given subset (optionally per condition)\n",
    "    def _fit_core(df_uni_sub, truth_sub, cond_label=\"ALL\"):\n",
    "        # ----- Matrix R: trials x models -----\n",
    "        R = df_uni_sub.pivot_table(\n",
    "                index=[\"image_id\",\"condition\"],\n",
    "                columns=\"model_name\",\n",
    "                values=\"pred_bin\",\n",
    "                aggfunc=\"mean\"\n",
    "            ).sort_index()\n",
    "\n",
    "        # Align truth to R\n",
    "        y = truth_sub.reindex(R.index).to_numpy()\n",
    "\n",
    "        # ----- Δμ by model: mean(pred|TP=1) - mean(pred|TP=0) -----\n",
    "        # Compute from the long df (not just R) to use all raw rows\n",
    "        sub_keys = set(map(tuple, R.index.to_frame(index=False).to_records(index=False)))\n",
    "        mask = df.set_index([\"image_id\",\"condition\"]).index.map(tuple).isin(sub_keys)\n",
    "        df_sub = df.loc[mask, [\"model_name\",\"TP\",\"pred_bin\"]].copy()\n",
    "\n",
    "        means_by_tp = (\n",
    "            df_sub.groupby([\"model_name\",\"TP\"])[\"pred_bin\"]\n",
    "                  .mean().unstack(\"TP\")  # columns {0,1}\n",
    "        )\n",
    "        if 0 not in means_by_tp.columns: means_by_tp[0] = np.nan\n",
    "        if 1 not in means_by_tp.columns: means_by_tp[1] = np.nan\n",
    "        Delta_mu = (means_by_tp[1] - means_by_tp[0]).fillna(0.0)\n",
    "        Delta_mu = Delta_mu.reindex(R.columns).fillna(0.0).to_numpy(dtype=float)  # (P,)\n",
    "\n",
    "        # ----- Prepare X for covariance -----\n",
    "        X = R.copy()  # rows=trials, cols=models\n",
    "        if center_by_model:\n",
    "            X = X.subtract(X.mean(axis=0, skipna=True), axis=1)\n",
    "        if standardize:\n",
    "            col_stds = X.std(axis=0, ddof=1, skipna=True).replace(0, np.nan)\n",
    "            X = X.divide(col_stds, axis=1)\n",
    "        # Missing model predictions -> 0 after centering (model-at-mean)\n",
    "        X = X.fillna(0.0)\n",
    "        X_np = X.to_numpy(dtype=float)\n",
    "        N, P = X_np.shape\n",
    "\n",
    "        # ----- Covariance & weights -----\n",
    "        Sigma = np.cov(X_np, rowvar=False, ddof=1) if P > 1 else np.array([[np.var(X_np, ddof=1)]])\n",
    "        Sigma_reg = Sigma + reg_lambda * np.eye(P)\n",
    "        try:\n",
    "            w = np.linalg.solve(Sigma_reg, Delta_mu)\n",
    "        except np.linalg.LinAlgError:\n",
    "            w = np.linalg.pinv(Sigma_reg) @ Delta_mu\n",
    "\n",
    "        # ----- Decision variable & threshold sweep -----\n",
    "        D = X_np @ w\n",
    "        D_sorted = np.unique(D)\n",
    "        if len(D_sorted) == 1:\n",
    "            crit_best = D_sorted[0]\n",
    "            pred = np.full_like(D, fill_value=int(y.mean() >= 0.5))\n",
    "            best_acc = np.mean(pred == y)\n",
    "        else:\n",
    "            mids = (D_sorted[:-1] + D_sorted[1:]) / 2.0\n",
    "            cands = np.concatenate(([-np.inf], mids, [np.inf]))\n",
    "            best_acc, crit_best, pred = -1.0, None, None\n",
    "            for c in cands:\n",
    "                p = (D >= c).astype(int) if tie_rule == \">=\" else (D > c).astype(int)\n",
    "                acc = (p == y).mean()\n",
    "                if acc > best_acc:\n",
    "                    best_acc, crit_best, pred = acc, c, p\n",
    "\n",
    "        # ----- Tables -----\n",
    "        trial_table = (\n",
    "            pd.DataFrame({\n",
    "                \"D\": D,\n",
    "                \"pred\": pred.astype(int),\n",
    "                \"truth\": y,\n",
    "            }, index=R.index)\n",
    "            .reset_index()\n",
    "            .assign(correct=lambda t: (t[\"pred\"] == t[\"truth\"]).astype(int))\n",
    "        )\n",
    "\n",
    "        by_condition = (\n",
    "            trial_table.groupby(\"condition\", as_index=False)\n",
    "                       .agg(trials=(\"image_id\",\"nunique\"),\n",
    "                            accuracy=(\"correct\",\"mean\"),\n",
    "                            D_mean=(\"D\",\"mean\"),\n",
    "                            D_std=(\"D\",\"std\"))\n",
    "                       .sort_values(\"condition\")\n",
    "        )\n",
    "\n",
    "        Delta_mu_series = pd.Series(Delta_mu, index=R.columns, name=\"Delta_mu\")\n",
    "        weights_df = (\n",
    "            pd.DataFrame({\"weight\": w}, index=R.columns)\n",
    "              .join(Delta_mu_series, how=\"left\")\n",
    "              .reset_index().rename(columns={\"index\":\"model_name\"})\n",
    "              .assign(Delta_mu=lambda d: d[\"Delta_mu\"].astype(float))\n",
    "              .sort_values(\"weight\", ascending=False)\n",
    "              .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        rank_sigma = int(np.linalg.matrix_rank(Sigma))\n",
    "        summary = {\n",
    "            \"condition_fit\": cond_label,\n",
    "            \"trials\": int(N),\n",
    "            \"n_models\": int(P),\n",
    "            \"rank_Sigma\": rank_sigma,\n",
    "            \"lambda\": reg_lambda,\n",
    "            \"best_threshold\": float(crit_best),\n",
    "            \"overall_accuracy\": float(trial_table[\"correct\"].mean()),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"trial_table\": trial_table,\n",
    "            \"by_condition\": by_condition,\n",
    "            \"weights_df\": weights_df,\n",
    "            \"R_matrix\": R,\n",
    "            \"X_centered\": X,\n",
    "            \"Sigma\": Sigma,\n",
    "            \"w\": w,\n",
    "            \"summary\": summary\n",
    "        }\n",
    "\n",
    "    results = {}\n",
    "    if fit_per_condition:\n",
    "        for cond, g in df_uni.groupby(\"condition\"):\n",
    "            truth_sub = truth_ic.loc[truth_ic.index.get_level_values(\"condition\") == cond]\n",
    "            res = _fit_core(g, truth_sub, cond_label=cond)\n",
    "            results[cond] = res\n",
    "        # Also compute a pooled “report” by concatenating summaries\n",
    "        pooled_summary = pd.DataFrame([v[\"summary\"] for v in results.values()])\n",
    "        results[\"__summary_per_condition__\"] = pooled_summary\n",
    "    else:\n",
    "        res = _fit_core(df_uni, truth_ic, cond_label=\"ALL\")\n",
    "        results[\"ALL\"] = res\n",
    "\n",
    "    return results\n",
    "\n",
    "# =========================\n",
    "# Example usage\n",
    "# =========================\n",
    "results = wlc_models(models_df, center_by_model=True, standardize=False,\n",
    "                      reg_lambda=1e-6, tie_rule=\">\", fit_per_condition=False)\n",
    "summary = results[\"ALL\"][\"summary\"]\n",
    "display(pd.DataFrame([summary]))\n",
    "display(results[\"ALL\"][\"by_condition\"])\n",
    "display(results[\"ALL\"][\"weights_df\"].head(12))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flexwisdom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
